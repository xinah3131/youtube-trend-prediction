{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ebbc2dc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns #Exploratary Plot\n",
    "import matplotlib.pylab as plt\n",
    "import os\n",
    "import pickle\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_selection import SelectKBest, chi2\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import GridSearchCV, train_test_split\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import classification_report\n",
    "plt.style.use('ggplot')\n",
    "pd.options.display.max_rows = 4000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6fea09e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(r'C:\\Users\\LEGION\\Desktop\\MMU\\Data Science Fundamental\\Project\\Prediction of Video\\dataset\\merged.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "85050d87",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Unnamed: 0', 'videoID', 'title', 'publishedAt', 'channelId',\n",
       "       'channelTitle', 'categoryId', 'tags', 'views', 'likes', 'comments',\n",
       "       'thumbnailLink', 'dayOfWeek', 'daytime', 'duration', 'trendingOrNot'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "33ca8fc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(['Unnamed: 0','videoID','publishedAt','channelId','channelTitle','thumbnailLink'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f4d287c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['title_length'] = df['title'].apply(lambda x: len(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e5f8d57a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Create a label encoder object\n",
    "le = LabelEncoder()\n",
    "\n",
    "# Fit the encoder to the data\n",
    "le.fit(df['daytime'])\n",
    "\n",
    "# Transform the data using the encoder\n",
    "df['daytime'] = le.transform(df['daytime'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8f76c6b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[(df.duration != 0)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4bc65578",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\LEGION\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\LEGION\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "import string\n",
    "import re\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n",
    "\n",
    "stop_words = set(stopwords.words('english'))  # set of English stop words\n",
    "\n",
    "def preprocess(text):\n",
    "    if not isinstance(text, str):\n",
    "        try:\n",
    "            text = str(text)\n",
    "        except:\n",
    "            raise TypeError('Input must be a string or a float')\n",
    "            \n",
    "  \n",
    "    # convert to lowercase\n",
    "    text = text.lower()\n",
    "    \n",
    "    # Remove URLs\n",
    "    text = re.sub(r'http\\S+', '', text)\n",
    "    # Remove special characters and punctuation\n",
    "    text = re.sub(r'[^a-zA-Z\\s]', '', text)\n",
    "    # tokenize the text\n",
    "    words = word_tokenize(text)\n",
    "    # remove stop words\n",
    "    words = [w for w in words if not w in stop_words]\n",
    "    \n",
    "    return words\n",
    "\n",
    "# Applying preprocessing function to title column\n",
    "df['clean_title'] = df['title'].apply(preprocess)\n",
    "df['clean_title_str'] = df['clean_title'].apply(lambda x: ' '.join(x))\n",
    "# df['clean_tags']  = df['tags'].apply(preprocess)\n",
    "# df['clean_tags_str'] = df['tags'].apply(lambda x: ' '.join(x))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "fd1e17f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import learning_curve\n",
    "\n",
    "def plot_learning_curve(estimator, title, X, y, ylim=None, cv=None, n_jobs=-1, train_sizes=np.linspace(.1, 1.0, 5)):\n",
    "    plt.figure()\n",
    "    plt.title(title)\n",
    "    if ylim is not None:\n",
    "        plt.ylim(*ylim)\n",
    "    plt.xlabel(\"Training examples\")\n",
    "    plt.ylabel(\"Score\")\n",
    "    train_sizes, train_scores, test_scores = learning_curve(\n",
    "        estimator, X, y, cv=cv, n_jobs=n_jobs, train_sizes=train_sizes)\n",
    "    train_scores_mean = np.mean(train_scores, axis=1)\n",
    "    train_scores_std = np.std(train_scores, axis=1)\n",
    "    test_scores_mean = np.mean(test_scores, axis=1)\n",
    "    test_scores_std = np.std(test_scores, axis=1)\n",
    "    plt.grid()\n",
    "\n",
    "    plt.fill_between(train_sizes, train_scores_mean - train_scores_std,\n",
    "                     train_scores_mean + train_scores_std, alpha=0.1,\n",
    "                     color=\"r\")\n",
    "    plt.fill_between(train_sizes, test_scores_mean - test_scores_std,\n",
    "                     test_scores_mean + test_scores_std, alpha=0.1, color=\"g\")\n",
    "    plt.plot(train_sizes, train_scores_mean, 'o-', color=\"r\",\n",
    "             label=\"Training score\")\n",
    "    plt.plot(train_sizes, test_scores_mean, 'o-', color=\"g\",\n",
    "             label=\"Cross-validation score\")\n",
    "\n",
    "    plt.legend(loc=\"best\")\n",
    "    return plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "a653f61c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.datasets import make_classification\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# X, y = make_classification(n_samples=1000, n_features=10, n_informative=5, n_redundant=2, random_state=42)\n",
    "X = df[['categoryId','dayOfWeek','daytime','title_length','duration']]\n",
    "y = df.trendingOrNot\n",
    "logreg = LogisticRegression()\n",
    "\n",
    "plot_learning_curve(logreg, \"Learning Curve (Logistic Regression)\", X, y, cv=5)\n",
    "plt.show()\n",
    "\n",
    "#High training Score, Low validation score = overfitting\n",
    "#Low Training score, Low Validaiton Score = undefitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "7a5cdcff",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\LEGION\\AppData\\Local\\Temp\\ipykernel_20772\\2285235928.py:6: FutureWarning: Dropping of nuisance columns in DataFrame reductions (with 'numeric_only=None') is deprecated; in a future version this will raise TypeError.  Select only valid columns before calling the reduction.\n",
      "  z_scores = (test_df - test_df.mean()) / df.std()\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>categoryId</th>\n",
       "      <th>comments</th>\n",
       "      <th>dayOfWeek</th>\n",
       "      <th>daytime</th>\n",
       "      <th>duration</th>\n",
       "      <th>likes</th>\n",
       "      <th>title_length</th>\n",
       "      <th>trendingOrNot</th>\n",
       "      <th>views</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.862596</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.625621</td>\n",
       "      <td>-0.235812</td>\n",
       "      <td>-0.170329</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-1.026074</td>\n",
       "      <td>1.593022</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.520824</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.625621</td>\n",
       "      <td>0.659446</td>\n",
       "      <td>-0.143659</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.834506</td>\n",
       "      <td>1.593022</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.520824</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.098296</td>\n",
       "      <td>-0.235812</td>\n",
       "      <td>-0.229507</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-1.026074</td>\n",
       "      <td>1.593022</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.691710</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.680270</td>\n",
       "      <td>1.554704</td>\n",
       "      <td>-0.208808</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.199186</td>\n",
       "      <td>1.593022</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.520824</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.098296</td>\n",
       "      <td>1.554704</td>\n",
       "      <td>-0.220882</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.481514</td>\n",
       "      <td>1.593022</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102786</th>\n",
       "      <td>-1.871580</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.152945</td>\n",
       "      <td>1.554704</td>\n",
       "      <td>0.272312</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.605966</td>\n",
       "      <td>-0.627731</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102787</th>\n",
       "      <td>-1.871580</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.625621</td>\n",
       "      <td>1.554704</td>\n",
       "      <td>0.276028</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.787486</td>\n",
       "      <td>-0.627731</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102788</th>\n",
       "      <td>-1.871580</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.098296</td>\n",
       "      <td>1.554704</td>\n",
       "      <td>0.270986</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.469826</td>\n",
       "      <td>-0.627731</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102789</th>\n",
       "      <td>-1.871580</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.429028</td>\n",
       "      <td>1.554704</td>\n",
       "      <td>0.259973</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.605966</td>\n",
       "      <td>-0.627731</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102790</th>\n",
       "      <td>0.179052</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.956353</td>\n",
       "      <td>0.659446</td>\n",
       "      <td>0.277355</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.605966</td>\n",
       "      <td>1.593022</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>93538 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        categoryId  comments  dayOfWeek   daytime  duration  likes  \\\n",
       "0         0.862596       NaN   0.625621 -0.235812 -0.170329    NaN   \n",
       "1         0.520824       NaN   0.625621  0.659446 -0.143659    NaN   \n",
       "2         0.520824       NaN   0.098296 -0.235812 -0.229507    NaN   \n",
       "3         0.691710       NaN   1.680270  1.554704 -0.208808    NaN   \n",
       "4         0.520824       NaN   0.098296  1.554704 -0.220882    NaN   \n",
       "...            ...       ...        ...       ...       ...    ...   \n",
       "102786   -1.871580       NaN   1.152945  1.554704  0.272312    NaN   \n",
       "102787   -1.871580       NaN   0.625621  1.554704  0.276028    NaN   \n",
       "102788   -1.871580       NaN   0.098296  1.554704  0.270986    NaN   \n",
       "102789   -1.871580       NaN  -0.429028  1.554704  0.259973    NaN   \n",
       "102790    0.179052       NaN  -0.956353  0.659446  0.277355    NaN   \n",
       "\n",
       "        title_length  trendingOrNot  views  \n",
       "0          -1.026074       1.593022    NaN  \n",
       "1           0.834506       1.593022    NaN  \n",
       "2          -1.026074       1.593022    NaN  \n",
       "3           0.199186       1.593022    NaN  \n",
       "4          -0.481514       1.593022    NaN  \n",
       "...              ...            ...    ...  \n",
       "102786      1.605966      -0.627731    NaN  \n",
       "102787      1.787486      -0.627731    NaN  \n",
       "102788      1.469826      -0.627731    NaN  \n",
       "102789      1.605966      -0.627731    NaN  \n",
       "102790      1.605966       1.593022    NaN  \n",
       "\n",
       "[93538 rows x 9 columns]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "test_df = df[['categoryId','dayOfWeek','daytime','title_length','duration','trendingOrNot']].copy()\n",
    "sns.boxplot(data=test_df)\n",
    "plt.show()\n",
    "\n",
    "# Calculate the Z-score for each column\n",
    "z_scores = (test_df - test_df.mean()) / df.std()\n",
    "\n",
    "# Identify outliers using Z-score > 3 or < -3\n",
    "z_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "06f4651e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.96      0.84     33618\n",
      "           1       0.62      0.18      0.28     13151\n",
      "\n",
      "    accuracy                           0.74     46769\n",
      "   macro avg       0.68      0.57      0.56     46769\n",
      "weighted avg       0.71      0.74      0.68     46769\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "X = df[['categoryId','dayOfWeek','daytime','title_length','duration']]\n",
    "y = df['trendingOrNot']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.5, random_state=42)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "num_cols = ['title_length', 'duration']\n",
    "X_train[num_cols] = scaler.fit_transform(X_train[num_cols])\n",
    "X_test[num_cols] = scaler.transform(X_test[num_cols])\n",
    "\n",
    "model = LogisticRegression()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "#model.score(X_test,y_test)\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a41e10f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8251550138977978\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.90      0.88     13426\n",
      "           1       0.71      0.63      0.67      5282\n",
      "\n",
      "    accuracy                           0.83     18708\n",
      "   macro avg       0.79      0.77      0.78     18708\n",
      "weighted avg       0.82      0.83      0.82     18708\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_selection import SelectKBest, chi2\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Extract features using TF-IDF\n",
    "vectorizer = TfidfVectorizer()\n",
    "X_title = vectorizer.fit_transform(df['clean_title_str'])\n",
    "\n",
    "# Select the top 1000 features based on chi-squared test\n",
    "selector_title = SelectKBest(chi2, k=500)\n",
    "X_title = selector_title.fit_transform(X_title, df['trendingOrNot'])\n",
    "\n",
    "# Convert 'categoryId' and 'daysOfUploading' to a numpy array\n",
    "# X_numeric = df[['categoryId','title_length','duration']].to_numpy()\n",
    "# Scale 'title_length' and 'duration' features\n",
    "scaler = StandardScaler()\n",
    "X_numeric = scaler.fit_transform(df[['title_length', 'duration']].to_numpy())\n",
    "\n",
    "# Include 'categoryId' as a feature\n",
    "X_cat = df[['categoryId']].to_numpy()\n",
    "\n",
    "# Concatenate the selected features and convert to a numpy array\n",
    "X = np.concatenate((X_title.toarray(), X_cat,X_numeric), axis=1)\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "y = df['trendingOrNot']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Train the SGD classifier model\n",
    "clf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test set and evaluate the model\n",
    "y_pred = clf.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy:\", accuracy)\n",
    "print(classification_report(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c444542e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the trained model to a file\n",
    "filename = 'randomModel.sav'\n",
    "pickle.dump(clf, open(filename, 'wb'))\n",
    "\n",
    "# Save the vectorizer to a file\n",
    "vectorizer_filename = 'vectorizer.sav'\n",
    "pickle.dump(vectorizer, open(vectorizer_filename, 'wb'))\n",
    "\n",
    "# Save the selector_title to a file\n",
    "selector_title_filename = 'selector_title.sav'\n",
    "pickle.dump(selector_title, open(selector_title_filename, 'wb'))\n",
    "# Load the saved model from a file\n",
    "#clf = pickle.load(open(filename, 'rb'))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "5438a648",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the vectorizer from file\n",
    "vectorizer_filename = 'vectorizer.sav'\n",
    "with open(vectorizer_filename, 'rb') as f:\n",
    "    vectorizer = pickle.load(f)\n",
    "\n",
    "# Load the selector_title from file\n",
    "selector_title_filename = 'selector_title.sav'\n",
    "with open(selector_title_filename, 'rb') as f:\n",
    "    selector_title = pickle.load(f)\n",
    "filename = 'randomModel.sav'\n",
    "clf = pickle.load(open(filename, 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "ffc7cfdc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.27, 0.73]])"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_title = \"Pokémon: Twilight Wings | Episode 7 | Sky\"\n",
    "import string\n",
    "\n",
    "# Remove punctuation and spaces\n",
    "new_title = new_title.translate(str.maketrans('', '', string.punctuation)).replace(\" \", \"\")\n",
    "new_category_id = 2\n",
    "title_length = 34\n",
    "duration = 577 # 0 - Morning 1 - Afternoon 2 - Noon 3 - Night\n",
    "\n",
    "# Extract features using TF-IDF\n",
    "new_title_features = vectorizer.transform([new_title])\n",
    "\n",
    "# Select the top 500 features based on chi-squared test\n",
    "new_title_features = selector_title.transform(new_title_features)\n",
    "\n",
    "# Scale 'title_length' and 'duration' features\n",
    "new_numeric_features = scaler.transform([[title_length, duration]])\n",
    "\n",
    "# Include 'categoryId' as a feature\n",
    "new_cat_features = np.array([[new_category_id]])\n",
    "\n",
    "# Combine the features into a numpy array\n",
    "new_features = np.concatenate((new_title_features.toarray(), new_cat_features, new_numeric_features), axis=1)\n",
    "\n",
    "# Make a prediction on the new data point\n",
    "clf.predict_proba(new_features)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1038d9ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8091346855391799\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\LEGION\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "\n",
    "# Extract features using TF-IDF\n",
    "vectorizer = TfidfVectorizer()\n",
    "X = vectorizer.fit_transform(df['clean_title_str'])\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "y = df['trendingOrNot']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Train the logistic regression model\n",
    "clf = LogisticRegression()\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test set and evaluate the model\n",
    "y_pred = clf.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy:\", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b04b2703",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.72043626, 0.27956374]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.predict_proba(vectorizer.transform(['Cake Rescue Fixing Viral Cake']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "88000768",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7672653410305752\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\LEGION\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_selection import SelectKBest, chi2\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Extract features using TF-IDF\n",
    "vectorizer = TfidfVectorizer()\n",
    "X_title = vectorizer.fit_transform(df['clean_title_str'])\n",
    "\n",
    "# Select the top 1000 features based on chi-squared test\n",
    "selector_title = SelectKBest(chi2, k=100)\n",
    "X_title = selector_title.fit_transform(X_title, df['trendingOrNot'])\n",
    "\n",
    "# Convert 'categoryId' and 'daysOfUploading' to a numpy array\n",
    "X_numeric = df[['dayOfWeek','daytime']].to_numpy()\n",
    "\n",
    "# Concatenate the selected features and convert to a numpy array\n",
    "X = np.concatenate((X_title.toarray(), X_numeric), axis=1)\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "y = df['trendingOrNot']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Train the logistic regression model\n",
    "clf = LogisticRegression()\n",
    "clf.fit(X_train, y_train)\n",
    "# from sklearn.naive_bayes import MultinomialNB\n",
    "# clf = MultinomialNB()\n",
    "# clf.fit(X_train, y_train)\n",
    "# Make predictions on the test set and evaluate the model\n",
    "y_pred = clf.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy:\", accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5ee3f30",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "53432c32",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\LEGION\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\LEGION\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\LEGION\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\LEGION\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\LEGION\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\LEGION\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\LEGION\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\LEGION\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\LEGION\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\LEGION\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\LEGION\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\LEGION\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\LEGION\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\LEGION\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\LEGION\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\LEGION\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:372: FitFailedWarning: \n",
      "15 fits failed out of a total of 30.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "15 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\LEGION\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\LEGION\\anaconda3\\lib\\site-packages\\sklearn\\pipeline.py\", line 394, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"C:\\Users\\LEGION\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1461, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\LEGION\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 447, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "C:\\Users\\LEGION\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:969: UserWarning: One or more of the test scores are non-finite: [       nan 0.81941339        nan 0.81864727        nan 0.81842838]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\LEGION\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\LEGION\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:372: FitFailedWarning: \n",
      "15 fits failed out of a total of 15.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "15 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\LEGION\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\LEGION\\anaconda3\\lib\\site-packages\\sklearn\\pipeline.py\", line 394, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"C:\\Users\\LEGION\\anaconda3\\lib\\site-packages\\sklearn\\naive_bayes.py\", line 690, in fit\n",
      "    self._count(X, Y)\n",
      "  File \"C:\\Users\\LEGION\\anaconda3\\lib\\site-packages\\sklearn\\naive_bayes.py\", line 863, in _count\n",
      "    check_non_negative(X, \"MultinomialNB (input X)\")\n",
      "  File \"C:\\Users\\LEGION\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 1249, in check_non_negative\n",
      "    raise ValueError(\"Negative values in data passed to %s\" % whom)\n",
      "ValueError: Negative values in data passed to MultinomialNB (input X)\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "C:\\Users\\LEGION\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:969: UserWarning: One or more of the test scores are non-finite: [nan nan nan]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Negative values in data passed to MultinomialNB (input X)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[1;32mIn [39]\u001b[0m, in \u001b[0;36m<cell line: 63>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     60\u001b[0m logreg_grid\u001b[38;5;241m.\u001b[39mfit(X_train, y_train)\n\u001b[0;32m     62\u001b[0m nb_grid \u001b[38;5;241m=\u001b[39m GridSearchCV(nb_pipe, nb_params, cv\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5\u001b[39m)\n\u001b[1;32m---> 63\u001b[0m \u001b[43mnb_grid\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     65\u001b[0m \u001b[38;5;66;03m# Fit the ensemble model using the best models from grid search\u001b[39;00m\n\u001b[0;32m     66\u001b[0m ensemble\u001b[38;5;241m.\u001b[39mestimators_ \u001b[38;5;241m=\u001b[39m [\n\u001b[0;32m     67\u001b[0m     (\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlogreg\u001b[39m\u001b[38;5;124m'\u001b[39m, logreg_grid\u001b[38;5;241m.\u001b[39mbest_estimator_),\n\u001b[0;32m     68\u001b[0m     (\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnb\u001b[39m\u001b[38;5;124m'\u001b[39m, nb_grid\u001b[38;5;241m.\u001b[39mbest_estimator_)\n\u001b[0;32m     69\u001b[0m ]\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:926\u001b[0m, in \u001b[0;36mBaseSearchCV.fit\u001b[1;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[0;32m    924\u001b[0m refit_start_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[0;32m    925\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m y \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 926\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbest_estimator_\u001b[38;5;241m.\u001b[39mfit(X, y, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_params)\n\u001b[0;32m    927\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    928\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbest_estimator_\u001b[38;5;241m.\u001b[39mfit(X, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_params)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\pipeline.py:394\u001b[0m, in \u001b[0;36mPipeline.fit\u001b[1;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[0;32m    392\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_final_estimator \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpassthrough\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m    393\u001b[0m         fit_params_last_step \u001b[38;5;241m=\u001b[39m fit_params_steps[\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msteps[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m][\u001b[38;5;241m0\u001b[39m]]\n\u001b[1;32m--> 394\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_final_estimator\u001b[38;5;241m.\u001b[39mfit(Xt, y, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_params_last_step)\n\u001b[0;32m    396\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\naive_bayes.py:690\u001b[0m, in \u001b[0;36m_BaseDiscreteNB.fit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m    688\u001b[0m n_classes \u001b[38;5;241m=\u001b[39m Y\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m]\n\u001b[0;32m    689\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_init_counters(n_classes, n_features)\n\u001b[1;32m--> 690\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_count\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mY\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    691\u001b[0m alpha \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_alpha()\n\u001b[0;32m    692\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_update_feature_log_prob(alpha)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\naive_bayes.py:863\u001b[0m, in \u001b[0;36mMultinomialNB._count\u001b[1;34m(self, X, Y)\u001b[0m\n\u001b[0;32m    861\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_count\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, Y):\n\u001b[0;32m    862\u001b[0m     \u001b[38;5;124;03m\"\"\"Count and smooth feature occurrences.\"\"\"\u001b[39;00m\n\u001b[1;32m--> 863\u001b[0m     \u001b[43mcheck_non_negative\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mMultinomialNB (input X)\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m    864\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfeature_count_ \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m safe_sparse_dot(Y\u001b[38;5;241m.\u001b[39mT, X)\n\u001b[0;32m    865\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclass_count_ \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m Y\u001b[38;5;241m.\u001b[39msum(axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:1249\u001b[0m, in \u001b[0;36mcheck_non_negative\u001b[1;34m(X, whom)\u001b[0m\n\u001b[0;32m   1246\u001b[0m     X_min \u001b[38;5;241m=\u001b[39m X\u001b[38;5;241m.\u001b[39mmin()\n\u001b[0;32m   1248\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m X_min \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m-> 1249\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNegative values in data passed to \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m whom)\n",
      "\u001b[1;31mValueError\u001b[0m: Negative values in data passed to MultinomialNB (input X)"
     ]
    }
   ],
   "source": [
    "# Define the features\n",
    "vectorizer = TfidfVectorizer()\n",
    "X_title = vectorizer.fit_transform(df['clean_title_str'])\n",
    "selector_title = SelectKBest(chi2, k=10000)\n",
    "X_title = selector_title.fit_transform(X_title, df['trendingOrNot'])\n",
    "X_numeric = df[['categoryId', 'dayOfWeek','daytime']].to_numpy()\n",
    "X = np.concatenate((X_title.toarray(), X_numeric), axis=1)\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "y = df['trendingOrNot']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Define the models to use\n",
    "logreg = LogisticRegression(random_state=42)\n",
    "nb = MultinomialNB()\n",
    "\n",
    "# Define the pipeline for the logistic regression model\n",
    "logreg_pipe = Pipeline([\n",
    "    ('clf', logreg)\n",
    "])\n",
    "\n",
    "# Define the pipeline for the Naive Bayes model\n",
    "nb_pipe = Pipeline([\n",
    "    ('clf', nb)\n",
    "])\n",
    "\n",
    "# Define the ensemble model\n",
    "ensemble = VotingClassifier(\n",
    "    estimators=[('logreg', logreg_pipe), ('nb', nb_pipe)],\n",
    "    voting='soft'\n",
    ")\n",
    "\n",
    "# Define the hyperparameters to tune for the logistic regression model\n",
    "logreg_params = {\n",
    "    'clf__C': [0.1, 1, 10],\n",
    "    'clf__penalty': ['l1', 'l2']\n",
    "}\n",
    "\n",
    "# Define the hyperparameters to tune for the Naive Bayes model\n",
    "nb_params = {\n",
    "    'clf__alpha': [0.1, 1, 10],\n",
    "}\n",
    "\n",
    "# Perform grid search to find the best hyperparameters for each model\n",
    "logreg_grid = GridSearchCV(logreg_pipe, logreg_params, cv=5)\n",
    "logreg_grid.fit(X_train, y_train)\n",
    "\n",
    "nb_grid = GridSearchCV(nb_pipe, nb_params, cv=5)\n",
    "nb_grid.fit(X_train, y_train)\n",
    "\n",
    "# Fit the ensemble model using the best models from grid search\n",
    "ensemble.estimators_ = [\n",
    "    ('logreg', logreg_grid.best_estimator_),\n",
    "    ('nb', nb_grid.best_estimator_)\n",
    "]\n",
    "ensemble.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test set and evaluate the model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a650733f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Save the trained model to a file\n",
    "filename = 'ensemble_model.sav'\n",
    "#pickle.dump(ensemble, open(filename, 'wb'))\n",
    "\n",
    "# Load the saved model from a file\n",
    "loaded_model = pickle.load(open(filename, 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "6d76b561",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8086482805583929\n"
     ]
    }
   ],
   "source": [
    "y_pred = loaded_model.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy:\", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c6d970d4",
   "metadata": {},
   "outputs": [
    {
     "ename": "NotFittedError",
     "evalue": "The TF-IDF vectorizer is not fitted",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNotFittedError\u001b[0m                            Traceback (most recent call last)",
      "Input \u001b[1;32mIn [15]\u001b[0m, in \u001b[0;36m<cell line: 7>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      4\u001b[0m daytime \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m3\u001b[39m \u001b[38;5;66;03m# 0 - Morning 1 - Afternoon 2 - Noon 3 - Night\u001b[39;00m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;66;03m# Extract features using TF-IDF\u001b[39;00m\n\u001b[1;32m----> 7\u001b[0m new_title_features \u001b[38;5;241m=\u001b[39m \u001b[43mvectorizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtransform\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43mnew_title\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      9\u001b[0m \u001b[38;5;66;03m# Select the top 1000 features based on chi-squared test\u001b[39;00m\n\u001b[0;32m     10\u001b[0m new_title_features \u001b[38;5;241m=\u001b[39m selector_title\u001b[38;5;241m.\u001b[39mtransform(new_title_features)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:2099\u001b[0m, in \u001b[0;36mTfidfVectorizer.transform\u001b[1;34m(self, raw_documents)\u001b[0m\n\u001b[0;32m   2083\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mtransform\u001b[39m(\u001b[38;5;28mself\u001b[39m, raw_documents):\n\u001b[0;32m   2084\u001b[0m     \u001b[38;5;124;03m\"\"\"Transform documents to document-term matrix.\u001b[39;00m\n\u001b[0;32m   2085\u001b[0m \n\u001b[0;32m   2086\u001b[0m \u001b[38;5;124;03m    Uses the vocabulary and document frequencies (df) learned by fit (or\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   2097\u001b[0m \u001b[38;5;124;03m        Tf-idf-weighted document-term matrix.\u001b[39;00m\n\u001b[0;32m   2098\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 2099\u001b[0m     \u001b[43mcheck_is_fitted\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmsg\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mThe TF-IDF vectorizer is not fitted\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m   2101\u001b[0m     X \u001b[38;5;241m=\u001b[39m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39mtransform(raw_documents)\n\u001b[0;32m   2102\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_tfidf\u001b[38;5;241m.\u001b[39mtransform(X, copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:1222\u001b[0m, in \u001b[0;36mcheck_is_fitted\u001b[1;34m(estimator, attributes, msg, all_or_any)\u001b[0m\n\u001b[0;32m   1217\u001b[0m     fitted \u001b[38;5;241m=\u001b[39m [\n\u001b[0;32m   1218\u001b[0m         v \u001b[38;5;28;01mfor\u001b[39;00m v \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mvars\u001b[39m(estimator) \u001b[38;5;28;01mif\u001b[39;00m v\u001b[38;5;241m.\u001b[39mendswith(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m v\u001b[38;5;241m.\u001b[39mstartswith(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m   1219\u001b[0m     ]\n\u001b[0;32m   1221\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m fitted:\n\u001b[1;32m-> 1222\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m NotFittedError(msg \u001b[38;5;241m%\u001b[39m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mname\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28mtype\u001b[39m(estimator)\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m})\n",
      "\u001b[1;31mNotFittedError\u001b[0m: The TF-IDF vectorizer is not fitted"
     ]
    }
   ],
   "source": [
    "new_title = \"This is Goodbye\"\n",
    "new_category_id = 10 \n",
    "days_uploading = 4 # 0 - Sunday ,..., 6- Saturday\n",
    "daytime = 3 # 0 - Morning 1 - Afternoon 2 - Noon 3 - Night\n",
    "\n",
    "# Extract features using TF-IDF\n",
    "new_title_features = vectorizer.transform([new_title])\n",
    "\n",
    "# Select the top 1000 features based on chi-squared test\n",
    "new_title_features = selector_title.transform(new_title_features)\n",
    "\n",
    "# Combine the features into a numpy array\n",
    "new_features = np.concatenate((new_title_features.toarray(), [[new_category_id,days_uploading,daytime ]]), axis=1)\n",
    "\n",
    "# Make a prediction on the new data point\n",
    "loaded_model.predict_proba(new_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "4b19b248",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['title', 'categoryId', 'tags', 'views', 'likes', 'comments',\n",
       "       'dayOfWeek', 'daytime', 'trendingOrNot', 'title_length', 'clean_title',\n",
       "       'clean_title_str'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3a66260e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.countplot(x='trendingOrNot',data=df,palette='hls')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ba7fdeab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "percentage of trend is 28.266586841711387\n",
      "percentage of no trend 71.73341315828861\n"
     ]
    }
   ],
   "source": [
    "trend = len(df[df['trendingOrNot']==1])\n",
    "noTrend = len(df[df['trendingOrNot']==0])\n",
    "pctOfTrend = trend/(trend+noTrend)\n",
    "print(\"percentage of trend is\", pctOfTrend*100)\n",
    "pctOfNoTrend = 100 - pctOfTrend*100\n",
    "print(\"percentage of no trend\", pctOfNoTrend)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "4e13283d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8249428474147575\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "rfc = RandomForestClassifier()\n",
    "rfc.fit(X_train_counts, y_train)\n",
    "y_pred = rfc.predict(X_test_counts)\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "ad1a4707",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 0, ..., 0, 0, 0], dtype=int64)"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rfc.predict(X_test_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d33ad4ce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['title', 'categoryId', 'tags', 'views', 'likes', 'comments',\n",
       "       'dayOfWeek', 'daytime', 'duration', 'trendingOrNot', 'title_length'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2a720687",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = df[['categoryId','dayOfWeek','daytime','title_length','duration','trendingOrNot']].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e52bf3d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#SMOTE\n",
    "X = test_df.loc[:, test_df.columns != 'trendingOrNot']\n",
    "y = test_df.loc[:, test_df.columns == 'trendingOrNot']\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.model_selection import train_test_split\n",
    "os = SMOTE(random_state=0)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=0)\n",
    "# columns = X_train.columns\n",
    "os_data_X,os_data_y=os.fit_resample(X_train, y_train)\n",
    "# os_data_X = pd.DataFrame(data=os_data_X,columns=columns )\n",
    "# os_data_y= pd.DataFrame(data=os_data_y,columns=['trendingOrNot'])\n",
    "# print(\"length of oversampled data is \",len(os_data_X))\n",
    "# print(\"Number of no trend  in oversampled data\",len(os_data_y[os_data_y['trendingOrNot']==0]))\n",
    "# print(\"Number of trend \",len(os_data_y[os_data_y['trendingOrNot']==1]))\n",
    "# print(\"Proportion of no subscription data in oversampled data is \",len(os_data_y[os_data_y['trendingOrNot']==0])/len(os_data_X))\n",
    "# print(\"Proportion of subscription data in oversampled data is \",len(os_data_y[os_data_y['trendingOrNot']==1])/len(os_data_X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "id": "be3dda80",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['views', 'likes', 'comments', 'trendingOrNot'], dtype=object)"
      ]
     },
     "execution_count": 186,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.columns.values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fda47351",
   "metadata": {},
   "source": [
    "# Data Balancing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "3e45aa82",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPgAAADnCAYAAAAzUZtFAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/YYfK9AAAACXBIWXMAAAsTAAALEwEAmpwYAAAcl0lEQVR4nO3deXQUVb4H8G+v6eyddGclQMgCCSHDDoIQkFUUeFF5KINvdBhnBkWYNzMq8NxGcRSdYXwsik9RQQ8iAiIII+ogDrIbJBAwkIQ9K+l0tk7SW3W/PzARSEhXh66+VdW/zzkcQuiivkf7m1tddeuWwu12u0EIkSUl6wCEEOFQwQmRMSo4ITJGBSdExqjghMgYFZwQGaOCEyJjVHBCZIwKToiMUcEJkTEqOCEyRgUnRMao4ITIGBWcEBmjgpOb2rVrF/r06YO0tDQsXbqUdRzSBQq6H5x0hOM49O7dG19//TWSkpIwdOhQbNiwAX379mUdjXiBRnDSoSNHjiAtLQ0pKSnQarV44IEHsG3bNtaxiJeo4KRDZWVl6N69e9ufk5KSUFZWxjAR6QoqOOlQR5/cFAoFgyTkVlDBSYeSkpJw+fLltj+XlpYiMTGRYSLSFVRw0qGhQ4eiuLgY58+fh91ux8cff4zp06ezjkW8pGYdgIiTWq3GqlWrMHnyZHAchzlz5iArK4t1LOIlukxGiIzRITohMkYFJ0TGqOCEyBgVnBAZo7PoMud2OMDVmsCZW39Vw/XT75y5BlxdDdw2G+Di4OY4gOOubqhSQaFSASo1FLpgqKIMUEUZoTIYoYo2QhUd0/a7Uh999bVEdOgsuoy4GhtgP3sa9pJC2IsLYS8pBFdVDgj9v1ipgjqpJ7TpmdCmZUKblgFNSh8odcHC7pd4RAWXKDfHwX66ALbC4z+XuVJEc8WVSqiTkttKH5Q1ANrUDNapAg4VXEJczU2wHj2IliN7Yc3bD1dDPetIXlHFxEE3dDSCh+dA138oFBoN60iyRwUXOWd1JVoO74X18F5YTxwFnA7WkXxCERwK3aDhV8s+dBRUEXrWkWSJCi5CLpsVzd/uQtOuT2Ev+pF1HOEpVQjqPwRhU+5D8G1j6ISdD1HBRcRRdgmWnZvQvHsnXJYG1nGYUBnjEDo5F2F33gNVtJF1HMmjgjPm5ji0HN4Ly85NsB3/Xvgz3lKhViN4xB0Iu3sGdNmDWaeRLCo4I267DY2ffwLL9o/BmapYxxE1dc8URNz7K4SMuwsKJc3N8gYV3M/cHIemf32OhvVvg6u5wjqOpGh6piLyV48h+LYxrKNIBhXcj5r370b9B6vhLL3AOoqkafv2h/7h+QjKGsA6iuhRwf3AejwP9WtXwl50inUUWdENHYXIhx+HNjmNdRTRooILyFlRito3X4X1h4Oso8iXUomQO+6C/rd/hCo8knUa0aGCC8DtdsOy4xPUr10Ft7WFdZyAoNQbEPX4YoSMGMs6iqhQwX3MWVEK8/IlsBUcZR0lIIWMvRP6uU/SaP4TKriP0KgtHjSa/4wK7gM0aosTjeZU8FvWvO9fML/+Ao3aIqWMNsL49N8QlJHNOgoTVPAucrvdaFj/Nho+XkPTS8VOo0X0/P9B6PiprJP4HRW8C1zWFpiXPYeWA3tYRyFeCLtnNvS/XhBQd6tRwb3krCqHacmf4ThfzDoK6QLdoBEwLHwZyrBw1lH8ggruBWvBUdS8vBCuhjrWUcgtUHfrAeNz/4AmKZl1FMFRwXmyfPkZat9cCjidrKMQH1CEhsG4+FXoBg5nHUVQVHAeGj/7CHXv/IN1DOJrGi2Mi5cieHgO6ySCoYJ70PDJWtSvW8U6BhGKWg3DU39FyO3jWScRBBW8E/UfvY2G9W+zjkGEplQh+s8vIHTsnayT+Bwtj3ETDRvfo3IHChcH87Ln0bzvX6yT+BwVvAONW9ej/oM3Wccg/uTiUPO3Z9ByeC/rJD5FBb+B5YstqFvzOusYhAWnE6ZXFsF67DDrJD5DBb+G9dgh1L75GusYhCWHHaZXFsIhk2W1qOA/cZRfRs3S/wFcHOsohDF3kwWmF/8El6WRdZRbRmfRAbiaLaj606/hvHyedRSfG7mnAKEqJVQKBVQKBXaOykSd3YnHjp1DaYsdScFavDkoBXpN+ydJf1tdj7/8eBmcG3iguxHzUuMBgPf2UqcbPBLG51+X9Nz1gB/B3S4Xal57RpblbrXxtj7YNbovdo7KBAC8ca4StxsjsHdsP9xujMCbZyvbbcO53Xjm1CWsG5qO3Tl9sb3cjKLGFt7by4H16AHUvb+CdYxbEvAFr1/3Bqzf72Mdw6++rqrDjG4GAMCMbgZ8VVXX7jX5dU1IDtGhZ0gQtEolpiVEtb2Oz/ZyYdm6Hk27d7CO0WUBXfCmb3ehcfM61jEEpQDw4JEi3LWvEOsvVQMATDYn4nRXH90bp9PAZGs/v77S6kCi7ufH+yYEa1Flc/DeXk7MK1+G7fRJ1jG6RH4fnHhyXDyL2uVLWMcQ3JYRfRCv08Jkc2D2kWKkhel4bdfRiRmFb6NJh8MO01+fQPybGyW3/FNAjuBuzoma11+A225jHUVw8TotAMAYpMHkOD3y65pgDFKjynp1NK6yOmAMav9zPkGnQbn152eRV7TYERuk+enf8ry93LjMJtS99TfWMbwWkAVv3PwBHMXyf+52s5ODxcm1ff2dqQF9woMxMVaPzWU1AIDNZTWYGKdvt23/yFCcb7LiUrMNdpcLn1fUtr2Oz/Zy1PztLjQf/JZ1DK8E3GUyx8WzqFzwIOB0eH6xxF1stuF3R88CAJxuN3ITozE/LQG1dicePXYO5S12JAZr8dbAFOi1alRa7VhYcBHrhqYDAL65Uo8XfrwMDm7cn2TE/LQEALjp9oFAGWVA/OpPJHOoHlAFd3NOVP15TkCM3kQ4IWPvhOHJl1jH4CWgDtED5dCcCEtKh+oBU3DHxbOo/+gd1jGITNS+8Qq4xnrWMTwKiIK73W6Yly8JiM/dxD9ctTWoW/O/rGN4FBAFb9m3G/Yz0pyoQMSr+ZudsF8oYR2jU7IvuJtzov5DWryBCMDlQv26N1in6JTsC9701XY4yy6xjkFkynrkO9hO5bOOcVOyLrjLZkXDBjqxRoRVt3Yl6wg3xbvgr73W8Uonf//7330Wxtcs2z8GV1PNOgaROfuPx0W7lhvvgp86dcqr77PmamxAwyZ53ylGxKN+3Rtwu1ysY7TjcX7hxo0bAQBOp7Pt61ZVVVWIiYkRJtktati8Du4m6S+5Q6TBcfEsmvf8U3SPKPZY8JqaqzcVuFyutq9bGY1GzJw5U5hkt8DV0gzLzs2sY5AA07DlA+kV/LHHHgMA9O7dGxMmTBA8kC80f/NPuFuaWMcgAcZ58RysBUehyx7MOkob3rcATZgwARUVFdi/fz/MZjOio6Nx++23IyEhQch8XWL5J43ehA3Lzs2iKjjvk2x5eXlYtGgRysrKEBYWhvLycixatAh5eXlC5vOa7eQxOEQ+u4jIV8vBPeDMJtYx2vAewTds2IAnn3wS/fr1a/veqVOn8N5772HIkCGChOsKy85NrCOQQOZ0wvLlZ4ic9QjrJAC8GMHNZjMyMzOv+15GRka7E28scbU1aD6wh3UMEuCadm2FmxPHAzR4Fzw5ORmff/75dd/bsWMHkpOTfZ2py5q+/IzuGCPMcaYq0Ux84b2iS1lZGV599VXYbDYYDAbU1NQgKCgITz31FJKSkoTO6ZHb5ULFnOngquW5CD+RlqCBwxH7EvsbUbxasonjOBQVFaG2thbR0dFIS0uDWi2OtbhshSdw5Yk5rGMQcpVShcSPvmK+dptX7VSpVO0+h4uFWA6JCAEAuDhYv9+H0HF3M43hseDz5s2DQnHzJe8VCgVWrmR/Nw0VnIhNy6G94i/43LlzO/z+uXPnsH37diiV7O84dVaUwnnpHOsYhFzH+sMhuB0OKDQazy8WiMeCZ2dnX/fn0tJSbNy4EadOncK0adMwZcoUwcLx1XLo36wjENKOu6UJ1hN5CB48glkG3p/Bq6qq8Mknn+CHH37A5MmT8eijjyIkJETIbLzR4TkRK+vhvUwL7vEsutlsxubNm7F//36MHz8eubm5iIiI8Fc+j1yNDSibPREQycQCQq6liolD4tqdzPbvcQSfP38+dDodpk2bhujo6A7nno8bN06QcHy0HD1A5SaixVVXwX72DLSpfZjs32PB09PToVAoOl25hWXBbaeOMds3IXzYTh0Tb8H/8pe/wO1248qVKzAajVCpVP7IxZujpJB1BEI6ZWf4HuV1jUuhUOCJJ57o9Ho4C26nE/bzdGsoETfRFxy4erNJRUWFkFm85rhYAjjsrGMQ0inn5YtwWa1M9s37MllWVhZefvlljBkzBkaj8bq/Y/UZ3F5ymsl+CfGKi4Pj3BkE9e3v913zLviZM2cQGxuLwsL2hxvsCk6fv4k02EsKxV3w559/XsgcXUIn2IhUsBqMvJrJVlBQgMbGRoSHhyM7OxtxcXFCZusUnWAjUiLqgr///vv48ssvYTAYoNfrUVdXhzVr1mDSpEmYM4fNPdjO8st0go1IhvPyRbg5Dgo/X2b2WPDt27cjPz8fL730EtLS0tq+X1JSgpUrV2L79u2YPn26oCE7wpnpmWNEQlwcXPW1UEUbPb/WhzxeJtu9ezfmz59/XbkBIC0tDfPmzcPu3bsFC9cZKjiRGhYPwvRYcLPZjJSUlA7/Li0tDWaz2eeh+BDT2tOE8MHV+v8967Hg4eHhKC8v7/DvysvLERYW5vNQfFDBidSIcgQfNWoUVq9e3W6kNpvNWL16NUaPHi1YuM5QwYnUsBjBPZ5kmzlzJpYtW4YFCxYgPT297Sx6cXEx+vXrx+zpovQZnEgNixHcY8HVajUWLlyIgoICFBQUoKGhAenp6bj33nvbLefkTy4awYnEsDjq5D3RJTs7m2mhb8TViueRSYTwweI9y7vgK1eu7PB2UbVaDYPBgKFDh/r1MUZua4vf9kWIL7ht/r+jjPftoiEhIfj+++/hdrsRHR0Nt9uNvLw8KJVKlJWV4ZlnnsG//+2f1U3dnNMv+yHEp5z+f9/yHsErKiqwePFiZGRktH2vqKgIGzduxLPPPov8/HysXbsWY8aMESTodWgNNiJBLJ44ynsELy4uRnp6+nXfS0lJQUnJ1Rs++vfv77dHCYvl0ayEeMUl4hE8OTkZGzZswMyZM6HVamG327Fp06a2z91Xrlzx26QXq1KLX09e5pd9EeIrMWFabPDzPnkXfN68eVixYgUeeughhIWFwWKxIDU1FQsWLAAAWCwWPPLII4IFvZZKpUC9jUZxIi2hOt4P8vUZrx4fDAAmkwm1tbWIiopqt3STvzhdLoxY9i2TfRPSVT2igrHlEf8+5cTrJwdqNBpERESA4zhUVVWhqqpKiFydUovggYeEeEul9P+qxLwP0fPz87F69WrU1dW1+7uNGzf6MhMvQWolbE6X3/dLSFdpVf4fmHgX/N1338V9992HsWPHQqvVCpmJl+gQLSoa2CxFS0hXGEKD/L5P3j9SLBYLJk6cKIpyA4AxVBw5COHLGOb/9yzvgo8bNw579uwRMotXjGH+/2lIyK1g8Z7lfYheXFyML774Atu2bYNer7/u71544QVf5/KIxU9DQm4Fi6NO3gUfN24c06eI3iiGRnAiMSzes7wLPnbsWAFjeM9An8GJxIhuBN+7dy9ycnIAAN98881NX8diZKfP4ERqRPcZfP/+/W0F/+677276OhYFj2FwyYGQrlKAzQju9VRVsbA6OIxdvhecNOOTAJOkD8bW3/p3mirg4TKZy+Xi9YsFnUaFZEMIk30T4q2MuHAm++30EH3WrFm8/hEWU1UBIDM+HGdNTUz2TYg3MsVY8FWrVrV9/cMPP+DQoUO45557YDQaYTKZsG3bNgwfPlzwkDeTGReBHScrme2fEL4y40VY8JiYmLavd+zYgaVLlyI0NBQAkJiYiJSUFCxevBiTJk0SNuVNsDrsIcRbrN6rvKeqNjc3w2azXfc9u92O5uZmn4fiq3dsGFQdrPRKiJgk6YMRrtMw2TfviS5jxozBkiVLcPfdd8NgMKCmpgZffPGFfxZZvInWE230OZyIGcsjTd4Ff/DBBxEfH48DBw6gtrYWer0ekydPxoQJE4TM5xGdaCNix+oEGyDh6+Ctth4vw8tfnWEdg5CbemfWIAxI0jPZN+8RHACOHz+OCxcuwGq9fqGF+++/36ehvDEq1QgFzkDSP6WIbOmDNchOjGS2f69WdDl48CCysrIQFCSeaaIxYUHIiA9HYWUj6yiEtHN7ioHJWmyteBd8//79eO2115itpNqZnFQjFZyIUk4q277wvkwWHh7edg1cbEYz/o9ISEe0KiVu6xXNNAPvgk+dOhUrVqxAUVFR23LJrJZNvlGfuHDER4jnYwMhADCoux4hWq9Oc/kc772vWbMGwNUpqzdiNRf9WqNTjdh0rIx1DELa5KSxP7KU/GWyVofO12D+5uOsYxDSZsfckYgL1zHN4PVK7CaTCUVFRUJkuSWDe0QhUsf2cIiQVlkJEczLDXhxiG4ymbB8+XJcuHABAPDhhx/i0KFDyM/Px9y5c4XKx5tGpcTUfglYn3eZdRRCcG//RNYRAHgxgr/99tsYOHAg1q1bB7X66s+FX/ziFzhx4oRg4bw1Y0A30K0nhLUInRqTMuJYxwDgRcFLSkqQm5sL5TUP/gsJCWF6N9mNkqJCMDyZ7WUJQqZmJUCnUbGOAcCLgkdGRqKy8vrFFUpLS0U38WXGwG6sI5AApgBwn4jeg7w/g0+bNg2vvvoqcnNz4XK5sG/fPmzduhW5ubkCxvPe6FQjEiJ09GBCwsSwnlHoESWetQK9ukx25MgR7N69G9XV1TAajZgwYQKGDRsmZL4uef/QBbz53TnWMUgA+ltuNsamx3h+oZ/wKrjL5cKLL76Ip59+GhoNm5UpvGFusmPq/+2Hg5PFJX4iEXHhQdj2u5FMby65Ea/P4EqlEleuXIFU5sREh2oxpW886xgkwDwwuLuoyg14cZJtxowZeOedd1BdXS2KddE9+e3IXtCqvJ7HQ0iXxIYH4T9FdHKtFe/P4J0t6iCGuegdeX1PMT6iiS/ED56ZnIH/+IU4Jrdci/dZ9NmzZ2PEiOsfveJ2u3H48GGfh/KVX9+WjG0nytFk51hHITLWyxCCqf0SWMfoEO9j2C1btiAmJua6X7Gxsfj000+FzHdL9MEa/NewHqxjEJmbOypFdJ+9W3kcwU+ePAkA4Diu7etWVVVVCA4OFiaZj/xycA9sOlaGmiY76yhEhvolRGBc71jWMW7K42fwefPmAbh6s8m1s9YUCgX0ej1yc3MxZMgQYVPeok3HSvHav8R3BxyRvrfuH4jBPaJYx7gp3ifZVq1ahccff1zoPIJwci7MfO8wLte1sI5CZGREr2ismDGAdYxOyWbBB0/yLtXisY3HaHll4hPBGhU2PDwM3fTi/ogaMBeKh/SIwn0DxHedkkjT4zmpoi83EEAFB4AFY9KQGMl+lQ0ibUN66EU5qaUjAXOI3irQDtVPvPJLqIJCAIUSCqUKff+wGs7mBpxdvwR2cxW00XFInf0c1CHtn59Vf+YILm17A3C7YBx2FxLumAUAvLeXI6kcmrcKqBEcCMxD9d6/X4asP76Nvn9YDQCo2LMBEWmDkL3wA0SkDULltxvabeN2cbi0dQV6/+YVZP35PZjzv0FL1QXe28uVVA7NWwVcwQE6VK87dQCGwZMAAIbBk1B7cn+71zRdPo0gYzcEGRKhVGsQ3f8O1J06wHt7OZLSoXmrgCx4sFaF5+7MDJD12xQofucp/Lh8LqoP7QAAOC210EYYAADaCAOcTXXttrLXm6CN/Pm+Zm1kDOwNJt7by02IRoVnJmdCoZDWuyZg1xke3CMKvx/VC2/tO886iqAyHlsObaQRDkstit55CrrYrk/dVQTIj8QbKQA8f1empA7NWwXkCN7qNyN6YUIf8U4z9AVt5NXZh5qwKOizRqHp8mmow6Jgb6gBANgbaqAO1Xe4nb2+uu3P9vpqaH4atflsLyePjEwW9XTUzgR0wQHg+SmZyIiT5xlgzt4Cztrc9nVDcR6C45Oh7zsSNUe/AgDUHP0K+qyR7bYNTcqA1VQGm7kCLqcD5uN7oO979XV8tpeLcb1j8NuRvVjH6LKAu0zWkcoGKx76MA/mZnndkGKrKUfJB88DuHpWPHrAeCSOnw1nU/3Vy1y1V6CNikXqg89BHRIBe70JFzYvQ+/fvAIAqCs8jMufvwG4XDAMnYLE8bMB4Kbby016TBje/eVgBGvFsQRyV1DBf3K8tA6PfnKM1nEjAICoEA3WPTgECZHS+9x9rYA/RG/VP0mPRRP7sI5BRECtVGDp9H6SLzdABb/O9OxEzB7SnXUMwtiiiX0wqLt4bwH1BhX8Bv99Rzru6y+tyQzEd/40Ll2Ua6t1FRW8Awsn9sbUfrTscqB5PCcVswbL6wiOCt4BhUKBZ+/MxORMcTwhkgjvd7f3wkPDe7KO4XN0Fr0TLrcbS3YVYsfJSs8vJpI1LycFDw9PZh1DEFRwD9xuN5Z+fQafHi9nHYUI4I93pOOXMj6xSgXn6X/3FGM9PURBNlQKBZ6a0Bv3yvzWYSq4F7YXlGPp12doMozERerU+Ou0fhieHM06iuCo4F46XlaPpz4rkN201kDRyxCKZfdko7uInuEtJCp4F1Q2WPHkZwU4XdXIOgrxwqhUA16amoVQbeDcJU0F7yKrg8OLuwrx9ekrrKMQHh4a3hOPjU6BUmILNtwqKvgteu/gBby171zALOIoNUFqJZ69MwOTMwNz4hIV3AeOXqrFi7sKUV5vZR2FXKNvfDiem5KJVGMY6yjMUMF9pNnuxMp/n8WW/DIazRnTqpR4ZGQyfjWsp2if+ukvVHAfy7tUiyU0mjNDo/b1qOACoNHc/2jU7hgVXEB5l2rx8pen6ammAstOiMDTd2bQqN0BKrjAnJwLW0+U492DF1DTRJNjfKlndAgeHZWC8TJfGfdWUMH9pMXOYcPRy/jgyEU02TnWcSQtNiwIj4xMxvTsRDoc94AK7md1LQ6sPXQBm/PLYHO6WMeRlAidGg8N64mZg5Kg00h3pVN/ooIzUtlgxZoD5/HPHyvp5hUPQrUqzBiYhIeG9UC4TsM6jqRQwRkzN9mxraAcW4+Xo6KBLq1dKz0mDPcN6IYpfeMQEkDzx32JCi4SLrcb+87WYHN+KQ6dNwfs5TWNSoFxvWMxY0A3DEjSs44jeVRwESqtbcaW4+X4/GQF6lscrOP4RXxEEO7t3w3/kZ2I6FAt6ziyQQUXMSfnwtHLddhbYsJ3Z02yO4RPMYYiJ9WInDQj+iVESO7RvFJABZeQoiuNbWUvrGyU3GG8SqnAwKRIjE6NQU6aEUkSfByv1FDBJcpkseG7syacKK/H6cpGnK9pBiey/5ValRJpMaHIjI/AwKRIjOxloLPgfkYFlwmrg0NxtQWFlY0orGrwe+mvLXNmXDgy4sKRagyFWkVL77NEBZcxq4NDaV0Lqi02mJrsMFlsMFnsMDXZUG2xoabJjpome6cTbhQAdBoVjKFaGMO0MIYFwRgahJgwLQw//R4TFoQkfTCVWYSo4AQAwLnc4FxuOF0uKKCASvnzLyJdVHBCZIyOqQiRMSo4ITJGBSdExqjgAW7OnDmIjY1Fv379WEchAqCCB7iHH34Yu3btYh2DCIQKHuBycnIQHS3/h/AFKio4ITJGBSdExqjghMgYFZwQGaOCB7hZs2ZhxIgROHPmDJKSkvDuu++yjkR8iOaiEyJjNIITImNUcEJkjApOiIxRwQmRMSo4ITJGBSdExqjghMgYFZwQGaOCEyJjVHBCZIwKToiMUcEJkTEqOCEyRgUnRMao4ITI2P8Db4q27y9TFUAAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "X = merged_df[['views']]\n",
    "y = merged_df.trendingOrNot\n",
    "rus = RandomUnderSampler(sampling_strategy=1)\n",
    "X_res,y_res = rus.fit_resample(X,y)\n",
    "\n",
    "ax = y_res.value_counts().plot.pie(autopct='%.2f')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "9766cf9e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    26184\n",
       "1    26184\n",
       "Name: trendingOrNot, dtype: int64"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_res.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bca4506",
   "metadata": {},
   "source": [
    "# Feature Engineer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "3a2f41e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "def remove_punc(text):\n",
    "    text = text.replace('|',' ')\n",
    "    text = \"\".join([chart for chart in text if chart not in string.punctuation])\n",
    "\n",
    "    return text\n",
    "\n",
    "merged_df['tags_clean'] = merged_df['tags'].apply(lambda x: remove_punc(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "91da3a39",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "def tokenizer(text):\n",
    "    tokens = re.split('\\W+',text)\n",
    "    return tokens\n",
    "\n",
    "df['tokens'] = df['tags_clean'].apply(lambda x: tokenizer(x.lower()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "a6f928b2",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\LEGION\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from collections import Counter\n",
    "nltk.download('stopwords')\n",
    "stopwords_en = nltk.corpus.stopwords.words('english')\n",
    "stopwords_sp = nltk.corpus.stopwords.words('spanish')\n",
    "\n",
    "stopwords = stopwords_en + stopwords_sp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "18bd91e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_stopwords(tokens):\n",
    "    tokens = [token for token in tokens if token not in stopwords]\n",
    "    return tokens\n",
    "\n",
    "df['tokens'] = df['tokens'].apply(lambda x: remove_stopwords(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "5b887f13",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_numb(tokens):\n",
    "    tokens = [token for token in tokens if token.isalpha()]\n",
    "    return tokens\n",
    "\n",
    "df['tokens'] = df['tokens'].apply(lambda x: remove_numb(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "6d19e58c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>categoryId</th>\n",
       "      <th>category_name</th>\n",
       "      <th>video_id</th>\n",
       "      <th>title</th>\n",
       "      <th>publishedAt</th>\n",
       "      <th>channelId</th>\n",
       "      <th>channelTitle</th>\n",
       "      <th>trending_date</th>\n",
       "      <th>tags</th>\n",
       "      <th>view_count</th>\n",
       "      <th>...</th>\n",
       "      <th>thumbnail_link</th>\n",
       "      <th>comments_disabled</th>\n",
       "      <th>ratings_disabled</th>\n",
       "      <th>description</th>\n",
       "      <th>count_max_view</th>\n",
       "      <th>month</th>\n",
       "      <th>untilTrend</th>\n",
       "      <th>hourUntilTrend</th>\n",
       "      <th>tags_clean</th>\n",
       "      <th>tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Autos &amp; Vehicles</td>\n",
       "      <td>5WjcDji3xYc</td>\n",
       "      <td>Honest Trailers | Avatar: The Last Airbender</td>\n",
       "      <td>2020-08-11T17:03:59Z</td>\n",
       "      <td>UCOpcACMWblDls9Z6GERVi1A</td>\n",
       "      <td>Screen Junkies</td>\n",
       "      <td>2020-08-12T00:00:00Z</td>\n",
       "      <td>screenjunkies|screen junkies|honest trailers|h...</td>\n",
       "      <td>833369</td>\n",
       "      <td>...</td>\n",
       "      <td>https://i.ytimg.com/vi/5WjcDji3xYc/default.jpg</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>►►Subscribe to ScreenJunkies!► https://fandom....</td>\n",
       "      <td>1457675</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>17</td>\n",
       "      <td>screenjunkies screen junkies honest trailers h...</td>\n",
       "      <td>[screenjunkies, screen, junkies, honest, trail...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Autos &amp; Vehicles</td>\n",
       "      <td>z5l8ovbw_6M</td>\n",
       "      <td>Don't be a Tourist</td>\n",
       "      <td>2020-08-10T21:28:49Z</td>\n",
       "      <td>UCDQBZcjYKP1J1Nu-Y0_D37Q</td>\n",
       "      <td>Tabbes</td>\n",
       "      <td>2020-08-12T00:00:00Z</td>\n",
       "      <td>drawing|humor|storytime animation|story|slice ...</td>\n",
       "      <td>1061892</td>\n",
       "      <td>...</td>\n",
       "      <td>https://i.ytimg.com/vi/z5l8ovbw_6M/default.jpg</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>This one is for all you full time travelersEMA...</td>\n",
       "      <td>1480119</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>21</td>\n",
       "      <td>drawing humor storytime animation story slice ...</td>\n",
       "      <td>[drawing, humor, storytime, animation, story, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>Autos &amp; Vehicles</td>\n",
       "      <td>yVdH3QacEXc</td>\n",
       "      <td>Selena Gomez - This is the Year (Official Prem...</td>\n",
       "      <td>2020-08-10T16:32:06Z</td>\n",
       "      <td>UCPNxhDvTcytIdvwXWAm43cA</td>\n",
       "      <td>Selena Gomez</td>\n",
       "      <td>2020-08-12T00:00:00Z</td>\n",
       "      <td>Selena Gomez|David Henrie|Dixie D’Amelio|Charl...</td>\n",
       "      <td>1523818</td>\n",
       "      <td>...</td>\n",
       "      <td>https://i.ytimg.com/vi/yVdH3QacEXc/default.jpg</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>Get your tickets here: https://thisistheyear.f...</td>\n",
       "      <td>2081043</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>16</td>\n",
       "      <td>Selena Gomez David Henrie Dixie D’Amelio Charl...</td>\n",
       "      <td>[selena, gomez, david, henrie, dixie, amelio, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>Autos &amp; Vehicles</td>\n",
       "      <td>A5RHu1lTv14</td>\n",
       "      <td>Satina Wants a Bedtime Story (SATINA SHORT #1)</td>\n",
       "      <td>2020-08-08T16:00:04Z</td>\n",
       "      <td>UC1fjSSxPEEHb7WqAdd6xChQ</td>\n",
       "      <td>Hannah Daigle</td>\n",
       "      <td>2020-08-12T00:00:00Z</td>\n",
       "      <td>[None]</td>\n",
       "      <td>605317</td>\n",
       "      <td>...</td>\n",
       "      <td>https://i.ytimg.com/vi/A5RHu1lTv14/default.jpg</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>MERCH STORE: https://sharkrobot.com/collection...</td>\n",
       "      <td>773068</td>\n",
       "      <td>8</td>\n",
       "      <td>3</td>\n",
       "      <td>16</td>\n",
       "      <td>None</td>\n",
       "      <td>[none]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>Autos &amp; Vehicles</td>\n",
       "      <td>PORP0q8nThs</td>\n",
       "      <td>Getting Suspended In High School</td>\n",
       "      <td>2020-08-07T20:52:37Z</td>\n",
       "      <td>UCRfg0SWjIHm_h95e4V8X5og</td>\n",
       "      <td>Young Don The Sauce God</td>\n",
       "      <td>2020-08-12T00:00:00Z</td>\n",
       "      <td>young don the sauce god|animations|animated|st...</td>\n",
       "      <td>741546</td>\n",
       "      <td>...</td>\n",
       "      <td>https://i.ytimg.com/vi/PORP0q8nThs/default.jpg</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>No Risk. No Reward. Getting Suspended In High ...</td>\n",
       "      <td>786231</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>20</td>\n",
       "      <td>young don the sauce god animations animated st...</td>\n",
       "      <td>[young, sauce, god, animations, animated, stor...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   categoryId     category_name     video_id  \\\n",
       "0           1  Autos & Vehicles  5WjcDji3xYc   \n",
       "1           1  Autos & Vehicles  z5l8ovbw_6M   \n",
       "2           1  Autos & Vehicles  yVdH3QacEXc   \n",
       "3           1  Autos & Vehicles  A5RHu1lTv14   \n",
       "4           1  Autos & Vehicles  PORP0q8nThs   \n",
       "\n",
       "                                               title           publishedAt  \\\n",
       "0       Honest Trailers | Avatar: The Last Airbender  2020-08-11T17:03:59Z   \n",
       "1                                 Don't be a Tourist  2020-08-10T21:28:49Z   \n",
       "2  Selena Gomez - This is the Year (Official Prem...  2020-08-10T16:32:06Z   \n",
       "3     Satina Wants a Bedtime Story (SATINA SHORT #1)  2020-08-08T16:00:04Z   \n",
       "4                   Getting Suspended In High School  2020-08-07T20:52:37Z   \n",
       "\n",
       "                  channelId             channelTitle         trending_date  \\\n",
       "0  UCOpcACMWblDls9Z6GERVi1A           Screen Junkies  2020-08-12T00:00:00Z   \n",
       "1  UCDQBZcjYKP1J1Nu-Y0_D37Q                   Tabbes  2020-08-12T00:00:00Z   \n",
       "2  UCPNxhDvTcytIdvwXWAm43cA             Selena Gomez  2020-08-12T00:00:00Z   \n",
       "3  UC1fjSSxPEEHb7WqAdd6xChQ            Hannah Daigle  2020-08-12T00:00:00Z   \n",
       "4  UCRfg0SWjIHm_h95e4V8X5og  Young Don The Sauce God  2020-08-12T00:00:00Z   \n",
       "\n",
       "                                                tags  view_count  ...  \\\n",
       "0  screenjunkies|screen junkies|honest trailers|h...      833369  ...   \n",
       "1  drawing|humor|storytime animation|story|slice ...     1061892  ...   \n",
       "2  Selena Gomez|David Henrie|Dixie D’Amelio|Charl...     1523818  ...   \n",
       "3                                             [None]      605317  ...   \n",
       "4  young don the sauce god|animations|animated|st...      741546  ...   \n",
       "\n",
       "                                   thumbnail_link  comments_disabled  \\\n",
       "0  https://i.ytimg.com/vi/5WjcDji3xYc/default.jpg              False   \n",
       "1  https://i.ytimg.com/vi/z5l8ovbw_6M/default.jpg              False   \n",
       "2  https://i.ytimg.com/vi/yVdH3QacEXc/default.jpg              False   \n",
       "3  https://i.ytimg.com/vi/A5RHu1lTv14/default.jpg              False   \n",
       "4  https://i.ytimg.com/vi/PORP0q8nThs/default.jpg              False   \n",
       "\n",
       "   ratings_disabled                                        description  \\\n",
       "0             False  ►►Subscribe to ScreenJunkies!► https://fandom....   \n",
       "1             False  This one is for all you full time travelersEMA...   \n",
       "2             False  Get your tickets here: https://thisistheyear.f...   \n",
       "3             False  MERCH STORE: https://sharkrobot.com/collection...   \n",
       "4             False  No Risk. No Reward. Getting Suspended In High ...   \n",
       "\n",
       "   count_max_view  month untilTrend  hourUntilTrend  \\\n",
       "0         1457675      8          0              17   \n",
       "1         1480119      8          1              21   \n",
       "2         2081043      8          1              16   \n",
       "3          773068      8          3              16   \n",
       "4          786231      8          4              20   \n",
       "\n",
       "                                          tags_clean  \\\n",
       "0  screenjunkies screen junkies honest trailers h...   \n",
       "1  drawing humor storytime animation story slice ...   \n",
       "2  Selena Gomez David Henrie Dixie D’Amelio Charl...   \n",
       "3                                               None   \n",
       "4  young don the sauce god animations animated st...   \n",
       "\n",
       "                                              tokens  \n",
       "0  [screenjunkies, screen, junkies, honest, trail...  \n",
       "1  [drawing, humor, storytime, animation, story, ...  \n",
       "2  [selena, gomez, david, henrie, dixie, amelio, ...  \n",
       "3                                             [none]  \n",
       "4  [young, sauce, god, animations, animated, stor...  \n",
       "\n",
       "[5 rows x 23 columns]"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "cc7a03a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_videos = df[['title','video_id']].drop_duplicates()\n",
    "\n",
    "c = Counter()\n",
    "def counter(text):\n",
    "      c.update(text)\n",
    "df.loc[unique_videos.index,'tokens'].apply(lambda x: counter(x))\n",
    "\n",
    "common_words_1 = [word[0] for word in c.most_common()[:300]]\n",
    "mono_words = list()\n",
    "for word in common_words_1:\n",
    "    if len(word)==1:\n",
    "        mono_words.append(word)\n",
    "\n",
    "for word in mono_words:\n",
    "    common_words_1.remove(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "3fa7120c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\LEGION\\AppData\\Local\\Temp\\ipykernel_3228\\1788549698.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[word] = df['tokens'].apply(lambda x: x.count(word))\n",
      "C:\\Users\\LEGION\\AppData\\Local\\Temp\\ipykernel_3228\\1788549698.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[word] = df['tokens'].apply(lambda x: x.count(word))\n",
      "C:\\Users\\LEGION\\AppData\\Local\\Temp\\ipykernel_3228\\1788549698.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[word] = df['tokens'].apply(lambda x: x.count(word))\n",
      "C:\\Users\\LEGION\\AppData\\Local\\Temp\\ipykernel_3228\\1788549698.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[word] = df['tokens'].apply(lambda x: x.count(word))\n",
      "C:\\Users\\LEGION\\AppData\\Local\\Temp\\ipykernel_3228\\1788549698.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[word] = df['tokens'].apply(lambda x: x.count(word))\n",
      "C:\\Users\\LEGION\\AppData\\Local\\Temp\\ipykernel_3228\\1788549698.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[word] = df['tokens'].apply(lambda x: x.count(word))\n",
      "C:\\Users\\LEGION\\AppData\\Local\\Temp\\ipykernel_3228\\1788549698.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[word] = df['tokens'].apply(lambda x: x.count(word))\n",
      "C:\\Users\\LEGION\\AppData\\Local\\Temp\\ipykernel_3228\\1788549698.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[word] = df['tokens'].apply(lambda x: x.count(word))\n",
      "C:\\Users\\LEGION\\AppData\\Local\\Temp\\ipykernel_3228\\1788549698.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[word] = df['tokens'].apply(lambda x: x.count(word))\n",
      "C:\\Users\\LEGION\\AppData\\Local\\Temp\\ipykernel_3228\\1788549698.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[word] = df['tokens'].apply(lambda x: x.count(word))\n",
      "C:\\Users\\LEGION\\AppData\\Local\\Temp\\ipykernel_3228\\1788549698.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[word] = df['tokens'].apply(lambda x: x.count(word))\n",
      "C:\\Users\\LEGION\\AppData\\Local\\Temp\\ipykernel_3228\\1788549698.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[word] = df['tokens'].apply(lambda x: x.count(word))\n",
      "C:\\Users\\LEGION\\AppData\\Local\\Temp\\ipykernel_3228\\1788549698.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[word] = df['tokens'].apply(lambda x: x.count(word))\n",
      "C:\\Users\\LEGION\\AppData\\Local\\Temp\\ipykernel_3228\\1788549698.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[word] = df['tokens'].apply(lambda x: x.count(word))\n",
      "C:\\Users\\LEGION\\AppData\\Local\\Temp\\ipykernel_3228\\1788549698.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[word] = df['tokens'].apply(lambda x: x.count(word))\n",
      "C:\\Users\\LEGION\\AppData\\Local\\Temp\\ipykernel_3228\\1788549698.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[word] = df['tokens'].apply(lambda x: x.count(word))\n",
      "C:\\Users\\LEGION\\AppData\\Local\\Temp\\ipykernel_3228\\1788549698.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[word] = df['tokens'].apply(lambda x: x.count(word))\n",
      "C:\\Users\\LEGION\\AppData\\Local\\Temp\\ipykernel_3228\\1788549698.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[word] = df['tokens'].apply(lambda x: x.count(word))\n",
      "C:\\Users\\LEGION\\AppData\\Local\\Temp\\ipykernel_3228\\1788549698.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[word] = df['tokens'].apply(lambda x: x.count(word))\n",
      "C:\\Users\\LEGION\\AppData\\Local\\Temp\\ipykernel_3228\\1788549698.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[word] = df['tokens'].apply(lambda x: x.count(word))\n",
      "C:\\Users\\LEGION\\AppData\\Local\\Temp\\ipykernel_3228\\1788549698.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[word] = df['tokens'].apply(lambda x: x.count(word))\n",
      "C:\\Users\\LEGION\\AppData\\Local\\Temp\\ipykernel_3228\\1788549698.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[word] = df['tokens'].apply(lambda x: x.count(word))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\LEGION\\AppData\\Local\\Temp\\ipykernel_3228\\1788549698.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[word] = df['tokens'].apply(lambda x: x.count(word))\n",
      "C:\\Users\\LEGION\\AppData\\Local\\Temp\\ipykernel_3228\\1788549698.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[word] = df['tokens'].apply(lambda x: x.count(word))\n",
      "C:\\Users\\LEGION\\AppData\\Local\\Temp\\ipykernel_3228\\1788549698.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[word] = df['tokens'].apply(lambda x: x.count(word))\n",
      "C:\\Users\\LEGION\\AppData\\Local\\Temp\\ipykernel_3228\\1788549698.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[word] = df['tokens'].apply(lambda x: x.count(word))\n",
      "C:\\Users\\LEGION\\AppData\\Local\\Temp\\ipykernel_3228\\1788549698.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[word] = df['tokens'].apply(lambda x: x.count(word))\n",
      "C:\\Users\\LEGION\\AppData\\Local\\Temp\\ipykernel_3228\\1788549698.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[word] = df['tokens'].apply(lambda x: x.count(word))\n",
      "C:\\Users\\LEGION\\AppData\\Local\\Temp\\ipykernel_3228\\1788549698.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[word] = df['tokens'].apply(lambda x: x.count(word))\n",
      "C:\\Users\\LEGION\\AppData\\Local\\Temp\\ipykernel_3228\\1788549698.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[word] = df['tokens'].apply(lambda x: x.count(word))\n",
      "C:\\Users\\LEGION\\AppData\\Local\\Temp\\ipykernel_3228\\1788549698.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[word] = df['tokens'].apply(lambda x: x.count(word))\n",
      "C:\\Users\\LEGION\\AppData\\Local\\Temp\\ipykernel_3228\\1788549698.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[word] = df['tokens'].apply(lambda x: x.count(word))\n",
      "C:\\Users\\LEGION\\AppData\\Local\\Temp\\ipykernel_3228\\1788549698.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[word] = df['tokens'].apply(lambda x: x.count(word))\n",
      "C:\\Users\\LEGION\\AppData\\Local\\Temp\\ipykernel_3228\\1788549698.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[word] = df['tokens'].apply(lambda x: x.count(word))\n",
      "C:\\Users\\LEGION\\AppData\\Local\\Temp\\ipykernel_3228\\1788549698.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[word] = df['tokens'].apply(lambda x: x.count(word))\n",
      "C:\\Users\\LEGION\\AppData\\Local\\Temp\\ipykernel_3228\\1788549698.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[word] = df['tokens'].apply(lambda x: x.count(word))\n",
      "C:\\Users\\LEGION\\AppData\\Local\\Temp\\ipykernel_3228\\1788549698.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[word] = df['tokens'].apply(lambda x: x.count(word))\n",
      "C:\\Users\\LEGION\\AppData\\Local\\Temp\\ipykernel_3228\\1788549698.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[word] = df['tokens'].apply(lambda x: x.count(word))\n",
      "C:\\Users\\LEGION\\AppData\\Local\\Temp\\ipykernel_3228\\1788549698.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[word] = df['tokens'].apply(lambda x: x.count(word))\n",
      "C:\\Users\\LEGION\\AppData\\Local\\Temp\\ipykernel_3228\\1788549698.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[word] = df['tokens'].apply(lambda x: x.count(word))\n",
      "C:\\Users\\LEGION\\AppData\\Local\\Temp\\ipykernel_3228\\1788549698.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[word] = df['tokens'].apply(lambda x: x.count(word))\n",
      "C:\\Users\\LEGION\\AppData\\Local\\Temp\\ipykernel_3228\\1788549698.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[word] = df['tokens'].apply(lambda x: x.count(word))\n",
      "C:\\Users\\LEGION\\AppData\\Local\\Temp\\ipykernel_3228\\1788549698.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[word] = df['tokens'].apply(lambda x: x.count(word))\n",
      "C:\\Users\\LEGION\\AppData\\Local\\Temp\\ipykernel_3228\\1788549698.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[word] = df['tokens'].apply(lambda x: x.count(word))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\LEGION\\AppData\\Local\\Temp\\ipykernel_3228\\1788549698.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[word] = df['tokens'].apply(lambda x: x.count(word))\n",
      "C:\\Users\\LEGION\\AppData\\Local\\Temp\\ipykernel_3228\\1788549698.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[word] = df['tokens'].apply(lambda x: x.count(word))\n",
      "C:\\Users\\LEGION\\AppData\\Local\\Temp\\ipykernel_3228\\1788549698.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[word] = df['tokens'].apply(lambda x: x.count(word))\n",
      "C:\\Users\\LEGION\\AppData\\Local\\Temp\\ipykernel_3228\\1788549698.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[word] = df['tokens'].apply(lambda x: x.count(word))\n",
      "C:\\Users\\LEGION\\AppData\\Local\\Temp\\ipykernel_3228\\1788549698.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[word] = df['tokens'].apply(lambda x: x.count(word))\n",
      "C:\\Users\\LEGION\\AppData\\Local\\Temp\\ipykernel_3228\\1788549698.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[word] = df['tokens'].apply(lambda x: x.count(word))\n",
      "C:\\Users\\LEGION\\AppData\\Local\\Temp\\ipykernel_3228\\1788549698.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[word] = df['tokens'].apply(lambda x: x.count(word))\n",
      "C:\\Users\\LEGION\\AppData\\Local\\Temp\\ipykernel_3228\\1788549698.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[word] = df['tokens'].apply(lambda x: x.count(word))\n",
      "C:\\Users\\LEGION\\AppData\\Local\\Temp\\ipykernel_3228\\1788549698.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[word] = df['tokens'].apply(lambda x: x.count(word))\n",
      "C:\\Users\\LEGION\\AppData\\Local\\Temp\\ipykernel_3228\\1788549698.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[word] = df['tokens'].apply(lambda x: x.count(word))\n",
      "C:\\Users\\LEGION\\AppData\\Local\\Temp\\ipykernel_3228\\1788549698.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[word] = df['tokens'].apply(lambda x: x.count(word))\n",
      "C:\\Users\\LEGION\\AppData\\Local\\Temp\\ipykernel_3228\\1788549698.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[word] = df['tokens'].apply(lambda x: x.count(word))\n",
      "C:\\Users\\LEGION\\AppData\\Local\\Temp\\ipykernel_3228\\1788549698.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[word] = df['tokens'].apply(lambda x: x.count(word))\n",
      "C:\\Users\\LEGION\\AppData\\Local\\Temp\\ipykernel_3228\\1788549698.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[word] = df['tokens'].apply(lambda x: x.count(word))\n",
      "C:\\Users\\LEGION\\AppData\\Local\\Temp\\ipykernel_3228\\1788549698.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[word] = df['tokens'].apply(lambda x: x.count(word))\n",
      "C:\\Users\\LEGION\\AppData\\Local\\Temp\\ipykernel_3228\\1788549698.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[word] = df['tokens'].apply(lambda x: x.count(word))\n",
      "C:\\Users\\LEGION\\AppData\\Local\\Temp\\ipykernel_3228\\1788549698.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[word] = df['tokens'].apply(lambda x: x.count(word))\n",
      "C:\\Users\\LEGION\\AppData\\Local\\Temp\\ipykernel_3228\\1788549698.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[word] = df['tokens'].apply(lambda x: x.count(word))\n",
      "C:\\Users\\LEGION\\AppData\\Local\\Temp\\ipykernel_3228\\1788549698.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[word] = df['tokens'].apply(lambda x: x.count(word))\n",
      "C:\\Users\\LEGION\\AppData\\Local\\Temp\\ipykernel_3228\\1788549698.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[word] = df['tokens'].apply(lambda x: x.count(word))\n",
      "C:\\Users\\LEGION\\AppData\\Local\\Temp\\ipykernel_3228\\1788549698.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[word] = df['tokens'].apply(lambda x: x.count(word))\n",
      "C:\\Users\\LEGION\\AppData\\Local\\Temp\\ipykernel_3228\\1788549698.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[word] = df['tokens'].apply(lambda x: x.count(word))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\LEGION\\AppData\\Local\\Temp\\ipykernel_3228\\1788549698.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[word] = df['tokens'].apply(lambda x: x.count(word))\n",
      "C:\\Users\\LEGION\\AppData\\Local\\Temp\\ipykernel_3228\\1788549698.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[word] = df['tokens'].apply(lambda x: x.count(word))\n",
      "C:\\Users\\LEGION\\AppData\\Local\\Temp\\ipykernel_3228\\1788549698.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[word] = df['tokens'].apply(lambda x: x.count(word))\n",
      "C:\\Users\\LEGION\\AppData\\Local\\Temp\\ipykernel_3228\\1788549698.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[word] = df['tokens'].apply(lambda x: x.count(word))\n",
      "C:\\Users\\LEGION\\AppData\\Local\\Temp\\ipykernel_3228\\1788549698.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[word] = df['tokens'].apply(lambda x: x.count(word))\n",
      "C:\\Users\\LEGION\\AppData\\Local\\Temp\\ipykernel_3228\\1788549698.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[word] = df['tokens'].apply(lambda x: x.count(word))\n",
      "C:\\Users\\LEGION\\AppData\\Local\\Temp\\ipykernel_3228\\1788549698.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[word] = df['tokens'].apply(lambda x: x.count(word))\n",
      "C:\\Users\\LEGION\\AppData\\Local\\Temp\\ipykernel_3228\\1788549698.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[word] = df['tokens'].apply(lambda x: x.count(word))\n",
      "C:\\Users\\LEGION\\AppData\\Local\\Temp\\ipykernel_3228\\1788549698.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[word] = df['tokens'].apply(lambda x: x.count(word))\n",
      "C:\\Users\\LEGION\\AppData\\Local\\Temp\\ipykernel_3228\\1788549698.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[word] = df['tokens'].apply(lambda x: x.count(word))\n",
      "C:\\Users\\LEGION\\AppData\\Local\\Temp\\ipykernel_3228\\1788549698.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[word] = df['tokens'].apply(lambda x: x.count(word))\n",
      "C:\\Users\\LEGION\\AppData\\Local\\Temp\\ipykernel_3228\\1788549698.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[word] = df['tokens'].apply(lambda x: x.count(word))\n",
      "C:\\Users\\LEGION\\AppData\\Local\\Temp\\ipykernel_3228\\1788549698.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[word] = df['tokens'].apply(lambda x: x.count(word))\n",
      "C:\\Users\\LEGION\\AppData\\Local\\Temp\\ipykernel_3228\\1788549698.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[word] = df['tokens'].apply(lambda x: x.count(word))\n",
      "C:\\Users\\LEGION\\AppData\\Local\\Temp\\ipykernel_3228\\1788549698.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[word] = df['tokens'].apply(lambda x: x.count(word))\n",
      "C:\\Users\\LEGION\\AppData\\Local\\Temp\\ipykernel_3228\\1788549698.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[word] = df['tokens'].apply(lambda x: x.count(word))\n",
      "C:\\Users\\LEGION\\AppData\\Local\\Temp\\ipykernel_3228\\1788549698.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[word] = df['tokens'].apply(lambda x: x.count(word))\n",
      "C:\\Users\\LEGION\\AppData\\Local\\Temp\\ipykernel_3228\\1788549698.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[word] = df['tokens'].apply(lambda x: x.count(word))\n",
      "C:\\Users\\LEGION\\AppData\\Local\\Temp\\ipykernel_3228\\1788549698.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[word] = df['tokens'].apply(lambda x: x.count(word))\n",
      "C:\\Users\\LEGION\\AppData\\Local\\Temp\\ipykernel_3228\\1788549698.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[word] = df['tokens'].apply(lambda x: x.count(word))\n",
      "C:\\Users\\LEGION\\AppData\\Local\\Temp\\ipykernel_3228\\1788549698.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[word] = df['tokens'].apply(lambda x: x.count(word))\n",
      "C:\\Users\\LEGION\\AppData\\Local\\Temp\\ipykernel_3228\\1788549698.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[word] = df['tokens'].apply(lambda x: x.count(word))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\LEGION\\AppData\\Local\\Temp\\ipykernel_3228\\1788549698.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[word] = df['tokens'].apply(lambda x: x.count(word))\n",
      "C:\\Users\\LEGION\\AppData\\Local\\Temp\\ipykernel_3228\\1788549698.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[word] = df['tokens'].apply(lambda x: x.count(word))\n",
      "C:\\Users\\LEGION\\AppData\\Local\\Temp\\ipykernel_3228\\1788549698.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[word] = df['tokens'].apply(lambda x: x.count(word))\n",
      "C:\\Users\\LEGION\\AppData\\Local\\Temp\\ipykernel_3228\\1788549698.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[word] = df['tokens'].apply(lambda x: x.count(word))\n",
      "C:\\Users\\LEGION\\AppData\\Local\\Temp\\ipykernel_3228\\1788549698.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[word] = df['tokens'].apply(lambda x: x.count(word))\n",
      "C:\\Users\\LEGION\\AppData\\Local\\Temp\\ipykernel_3228\\1788549698.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[word] = df['tokens'].apply(lambda x: x.count(word))\n",
      "C:\\Users\\LEGION\\AppData\\Local\\Temp\\ipykernel_3228\\1788549698.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[word] = df['tokens'].apply(lambda x: x.count(word))\n",
      "C:\\Users\\LEGION\\AppData\\Local\\Temp\\ipykernel_3228\\1788549698.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[word] = df['tokens'].apply(lambda x: x.count(word))\n",
      "C:\\Users\\LEGION\\AppData\\Local\\Temp\\ipykernel_3228\\1788549698.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[word] = df['tokens'].apply(lambda x: x.count(word))\n",
      "C:\\Users\\LEGION\\AppData\\Local\\Temp\\ipykernel_3228\\1788549698.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[word] = df['tokens'].apply(lambda x: x.count(word))\n",
      "C:\\Users\\LEGION\\AppData\\Local\\Temp\\ipykernel_3228\\1788549698.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[word] = df['tokens'].apply(lambda x: x.count(word))\n",
      "C:\\Users\\LEGION\\AppData\\Local\\Temp\\ipykernel_3228\\1788549698.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[word] = df['tokens'].apply(lambda x: x.count(word))\n",
      "C:\\Users\\LEGION\\AppData\\Local\\Temp\\ipykernel_3228\\1788549698.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[word] = df['tokens'].apply(lambda x: x.count(word))\n",
      "C:\\Users\\LEGION\\AppData\\Local\\Temp\\ipykernel_3228\\1788549698.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[word] = df['tokens'].apply(lambda x: x.count(word))\n",
      "C:\\Users\\LEGION\\AppData\\Local\\Temp\\ipykernel_3228\\1788549698.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[word] = df['tokens'].apply(lambda x: x.count(word))\n",
      "C:\\Users\\LEGION\\AppData\\Local\\Temp\\ipykernel_3228\\1788549698.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[word] = df['tokens'].apply(lambda x: x.count(word))\n",
      "C:\\Users\\LEGION\\AppData\\Local\\Temp\\ipykernel_3228\\1788549698.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[word] = df['tokens'].apply(lambda x: x.count(word))\n",
      "C:\\Users\\LEGION\\AppData\\Local\\Temp\\ipykernel_3228\\1788549698.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[word] = df['tokens'].apply(lambda x: x.count(word))\n",
      "C:\\Users\\LEGION\\AppData\\Local\\Temp\\ipykernel_3228\\1788549698.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[word] = df['tokens'].apply(lambda x: x.count(word))\n",
      "C:\\Users\\LEGION\\AppData\\Local\\Temp\\ipykernel_3228\\1788549698.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[word] = df['tokens'].apply(lambda x: x.count(word))\n",
      "C:\\Users\\LEGION\\AppData\\Local\\Temp\\ipykernel_3228\\1788549698.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[word] = df['tokens'].apply(lambda x: x.count(word))\n",
      "C:\\Users\\LEGION\\AppData\\Local\\Temp\\ipykernel_3228\\1788549698.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[word] = df['tokens'].apply(lambda x: x.count(word))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\LEGION\\AppData\\Local\\Temp\\ipykernel_3228\\1788549698.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[word] = df['tokens'].apply(lambda x: x.count(word))\n",
      "C:\\Users\\LEGION\\AppData\\Local\\Temp\\ipykernel_3228\\1788549698.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[word] = df['tokens'].apply(lambda x: x.count(word))\n",
      "C:\\Users\\LEGION\\AppData\\Local\\Temp\\ipykernel_3228\\1788549698.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[word] = df['tokens'].apply(lambda x: x.count(word))\n",
      "C:\\Users\\LEGION\\AppData\\Local\\Temp\\ipykernel_3228\\1788549698.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[word] = df['tokens'].apply(lambda x: x.count(word))\n",
      "C:\\Users\\LEGION\\AppData\\Local\\Temp\\ipykernel_3228\\1788549698.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[word] = df['tokens'].apply(lambda x: x.count(word))\n",
      "C:\\Users\\LEGION\\AppData\\Local\\Temp\\ipykernel_3228\\1788549698.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[word] = df['tokens'].apply(lambda x: x.count(word))\n",
      "C:\\Users\\LEGION\\AppData\\Local\\Temp\\ipykernel_3228\\1788549698.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[word] = df['tokens'].apply(lambda x: x.count(word))\n",
      "C:\\Users\\LEGION\\AppData\\Local\\Temp\\ipykernel_3228\\1788549698.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[word] = df['tokens'].apply(lambda x: x.count(word))\n",
      "C:\\Users\\LEGION\\AppData\\Local\\Temp\\ipykernel_3228\\1788549698.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[word] = df['tokens'].apply(lambda x: x.count(word))\n",
      "C:\\Users\\LEGION\\AppData\\Local\\Temp\\ipykernel_3228\\1788549698.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[word] = df['tokens'].apply(lambda x: x.count(word))\n",
      "C:\\Users\\LEGION\\AppData\\Local\\Temp\\ipykernel_3228\\1788549698.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[word] = df['tokens'].apply(lambda x: x.count(word))\n",
      "C:\\Users\\LEGION\\AppData\\Local\\Temp\\ipykernel_3228\\1788549698.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[word] = df['tokens'].apply(lambda x: x.count(word))\n",
      "C:\\Users\\LEGION\\AppData\\Local\\Temp\\ipykernel_3228\\1788549698.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[word] = df['tokens'].apply(lambda x: x.count(word))\n",
      "C:\\Users\\LEGION\\AppData\\Local\\Temp\\ipykernel_3228\\1788549698.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[word] = df['tokens'].apply(lambda x: x.count(word))\n",
      "C:\\Users\\LEGION\\AppData\\Local\\Temp\\ipykernel_3228\\1788549698.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[word] = df['tokens'].apply(lambda x: x.count(word))\n",
      "C:\\Users\\LEGION\\AppData\\Local\\Temp\\ipykernel_3228\\1788549698.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[word] = df['tokens'].apply(lambda x: x.count(word))\n",
      "C:\\Users\\LEGION\\AppData\\Local\\Temp\\ipykernel_3228\\1788549698.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[word] = df['tokens'].apply(lambda x: x.count(word))\n",
      "C:\\Users\\LEGION\\AppData\\Local\\Temp\\ipykernel_3228\\1788549698.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[word] = df['tokens'].apply(lambda x: x.count(word))\n",
      "C:\\Users\\LEGION\\AppData\\Local\\Temp\\ipykernel_3228\\1788549698.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[word] = df['tokens'].apply(lambda x: x.count(word))\n",
      "C:\\Users\\LEGION\\AppData\\Local\\Temp\\ipykernel_3228\\1788549698.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[word] = df['tokens'].apply(lambda x: x.count(word))\n",
      "C:\\Users\\LEGION\\AppData\\Local\\Temp\\ipykernel_3228\\1788549698.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[word] = df['tokens'].apply(lambda x: x.count(word))\n",
      "C:\\Users\\LEGION\\AppData\\Local\\Temp\\ipykernel_3228\\1788549698.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[word] = df['tokens'].apply(lambda x: x.count(word))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\LEGION\\AppData\\Local\\Temp\\ipykernel_3228\\1788549698.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[word] = df['tokens'].apply(lambda x: x.count(word))\n",
      "C:\\Users\\LEGION\\AppData\\Local\\Temp\\ipykernel_3228\\1788549698.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[word] = df['tokens'].apply(lambda x: x.count(word))\n",
      "C:\\Users\\LEGION\\AppData\\Local\\Temp\\ipykernel_3228\\1788549698.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[word] = df['tokens'].apply(lambda x: x.count(word))\n",
      "C:\\Users\\LEGION\\AppData\\Local\\Temp\\ipykernel_3228\\1788549698.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[word] = df['tokens'].apply(lambda x: x.count(word))\n",
      "C:\\Users\\LEGION\\AppData\\Local\\Temp\\ipykernel_3228\\1788549698.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[word] = df['tokens'].apply(lambda x: x.count(word))\n",
      "C:\\Users\\LEGION\\AppData\\Local\\Temp\\ipykernel_3228\\1788549698.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[word] = df['tokens'].apply(lambda x: x.count(word))\n",
      "C:\\Users\\LEGION\\AppData\\Local\\Temp\\ipykernel_3228\\1788549698.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[word] = df['tokens'].apply(lambda x: x.count(word))\n",
      "C:\\Users\\LEGION\\AppData\\Local\\Temp\\ipykernel_3228\\1788549698.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[word] = df['tokens'].apply(lambda x: x.count(word))\n",
      "C:\\Users\\LEGION\\AppData\\Local\\Temp\\ipykernel_3228\\1788549698.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[word] = df['tokens'].apply(lambda x: x.count(word))\n",
      "C:\\Users\\LEGION\\AppData\\Local\\Temp\\ipykernel_3228\\1788549698.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[word] = df['tokens'].apply(lambda x: x.count(word))\n",
      "C:\\Users\\LEGION\\AppData\\Local\\Temp\\ipykernel_3228\\1788549698.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[word] = df['tokens'].apply(lambda x: x.count(word))\n",
      "C:\\Users\\LEGION\\AppData\\Local\\Temp\\ipykernel_3228\\1788549698.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[word] = df['tokens'].apply(lambda x: x.count(word))\n",
      "C:\\Users\\LEGION\\AppData\\Local\\Temp\\ipykernel_3228\\1788549698.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[word] = df['tokens'].apply(lambda x: x.count(word))\n",
      "C:\\Users\\LEGION\\AppData\\Local\\Temp\\ipykernel_3228\\1788549698.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[word] = df['tokens'].apply(lambda x: x.count(word))\n",
      "C:\\Users\\LEGION\\AppData\\Local\\Temp\\ipykernel_3228\\1788549698.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[word] = df['tokens'].apply(lambda x: x.count(word))\n",
      "C:\\Users\\LEGION\\AppData\\Local\\Temp\\ipykernel_3228\\1788549698.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[word] = df['tokens'].apply(lambda x: x.count(word))\n",
      "C:\\Users\\LEGION\\AppData\\Local\\Temp\\ipykernel_3228\\1788549698.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[word] = df['tokens'].apply(lambda x: x.count(word))\n",
      "C:\\Users\\LEGION\\AppData\\Local\\Temp\\ipykernel_3228\\1788549698.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[word] = df['tokens'].apply(lambda x: x.count(word))\n",
      "C:\\Users\\LEGION\\AppData\\Local\\Temp\\ipykernel_3228\\1788549698.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[word] = df['tokens'].apply(lambda x: x.count(word))\n",
      "C:\\Users\\LEGION\\AppData\\Local\\Temp\\ipykernel_3228\\1788549698.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[word] = df['tokens'].apply(lambda x: x.count(word))\n",
      "C:\\Users\\LEGION\\AppData\\Local\\Temp\\ipykernel_3228\\1788549698.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[word] = df['tokens'].apply(lambda x: x.count(word))\n",
      "C:\\Users\\LEGION\\AppData\\Local\\Temp\\ipykernel_3228\\1788549698.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[word] = df['tokens'].apply(lambda x: x.count(word))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\LEGION\\AppData\\Local\\Temp\\ipykernel_3228\\1788549698.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[word] = df['tokens'].apply(lambda x: x.count(word))\n",
      "C:\\Users\\LEGION\\AppData\\Local\\Temp\\ipykernel_3228\\1788549698.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[word] = df['tokens'].apply(lambda x: x.count(word))\n",
      "C:\\Users\\LEGION\\AppData\\Local\\Temp\\ipykernel_3228\\1788549698.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[word] = df['tokens'].apply(lambda x: x.count(word))\n",
      "C:\\Users\\LEGION\\AppData\\Local\\Temp\\ipykernel_3228\\1788549698.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[word] = df['tokens'].apply(lambda x: x.count(word))\n",
      "C:\\Users\\LEGION\\AppData\\Local\\Temp\\ipykernel_3228\\1788549698.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[word] = df['tokens'].apply(lambda x: x.count(word))\n",
      "C:\\Users\\LEGION\\AppData\\Local\\Temp\\ipykernel_3228\\1788549698.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[word] = df['tokens'].apply(lambda x: x.count(word))\n",
      "C:\\Users\\LEGION\\AppData\\Local\\Temp\\ipykernel_3228\\1788549698.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[word] = df['tokens'].apply(lambda x: x.count(word))\n",
      "C:\\Users\\LEGION\\AppData\\Local\\Temp\\ipykernel_3228\\1788549698.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[word] = df['tokens'].apply(lambda x: x.count(word))\n",
      "C:\\Users\\LEGION\\AppData\\Local\\Temp\\ipykernel_3228\\1788549698.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[word] = df['tokens'].apply(lambda x: x.count(word))\n",
      "C:\\Users\\LEGION\\AppData\\Local\\Temp\\ipykernel_3228\\1788549698.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[word] = df['tokens'].apply(lambda x: x.count(word))\n",
      "C:\\Users\\LEGION\\AppData\\Local\\Temp\\ipykernel_3228\\1788549698.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[word] = df['tokens'].apply(lambda x: x.count(word))\n",
      "C:\\Users\\LEGION\\AppData\\Local\\Temp\\ipykernel_3228\\1788549698.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[word] = df['tokens'].apply(lambda x: x.count(word))\n",
      "C:\\Users\\LEGION\\AppData\\Local\\Temp\\ipykernel_3228\\1788549698.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[word] = df['tokens'].apply(lambda x: x.count(word))\n",
      "C:\\Users\\LEGION\\AppData\\Local\\Temp\\ipykernel_3228\\1788549698.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[word] = df['tokens'].apply(lambda x: x.count(word))\n",
      "C:\\Users\\LEGION\\AppData\\Local\\Temp\\ipykernel_3228\\1788549698.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[word] = df['tokens'].apply(lambda x: x.count(word))\n",
      "C:\\Users\\LEGION\\AppData\\Local\\Temp\\ipykernel_3228\\1788549698.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[word] = df['tokens'].apply(lambda x: x.count(word))\n",
      "C:\\Users\\LEGION\\AppData\\Local\\Temp\\ipykernel_3228\\1788549698.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[word] = df['tokens'].apply(lambda x: x.count(word))\n",
      "C:\\Users\\LEGION\\AppData\\Local\\Temp\\ipykernel_3228\\1788549698.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[word] = df['tokens'].apply(lambda x: x.count(word))\n",
      "C:\\Users\\LEGION\\AppData\\Local\\Temp\\ipykernel_3228\\1788549698.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[word] = df['tokens'].apply(lambda x: x.count(word))\n",
      "C:\\Users\\LEGION\\AppData\\Local\\Temp\\ipykernel_3228\\1788549698.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[word] = df['tokens'].apply(lambda x: x.count(word))\n",
      "C:\\Users\\LEGION\\AppData\\Local\\Temp\\ipykernel_3228\\1788549698.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[word] = df['tokens'].apply(lambda x: x.count(word))\n",
      "C:\\Users\\LEGION\\AppData\\Local\\Temp\\ipykernel_3228\\1788549698.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[word] = df['tokens'].apply(lambda x: x.count(word))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\LEGION\\AppData\\Local\\Temp\\ipykernel_3228\\1788549698.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[word] = df['tokens'].apply(lambda x: x.count(word))\n",
      "C:\\Users\\LEGION\\AppData\\Local\\Temp\\ipykernel_3228\\1788549698.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[word] = df['tokens'].apply(lambda x: x.count(word))\n",
      "C:\\Users\\LEGION\\AppData\\Local\\Temp\\ipykernel_3228\\1788549698.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[word] = df['tokens'].apply(lambda x: x.count(word))\n",
      "C:\\Users\\LEGION\\AppData\\Local\\Temp\\ipykernel_3228\\1788549698.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[word] = df['tokens'].apply(lambda x: x.count(word))\n",
      "C:\\Users\\LEGION\\AppData\\Local\\Temp\\ipykernel_3228\\1788549698.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[word] = df['tokens'].apply(lambda x: x.count(word))\n",
      "C:\\Users\\LEGION\\AppData\\Local\\Temp\\ipykernel_3228\\1788549698.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[word] = df['tokens'].apply(lambda x: x.count(word))\n",
      "C:\\Users\\LEGION\\AppData\\Local\\Temp\\ipykernel_3228\\1788549698.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[word] = df['tokens'].apply(lambda x: x.count(word))\n",
      "C:\\Users\\LEGION\\AppData\\Local\\Temp\\ipykernel_3228\\1788549698.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[word] = df['tokens'].apply(lambda x: x.count(word))\n",
      "C:\\Users\\LEGION\\AppData\\Local\\Temp\\ipykernel_3228\\1788549698.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[word] = df['tokens'].apply(lambda x: x.count(word))\n",
      "C:\\Users\\LEGION\\AppData\\Local\\Temp\\ipykernel_3228\\1788549698.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[word] = df['tokens'].apply(lambda x: x.count(word))\n",
      "C:\\Users\\LEGION\\AppData\\Local\\Temp\\ipykernel_3228\\1788549698.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[word] = df['tokens'].apply(lambda x: x.count(word))\n",
      "C:\\Users\\LEGION\\AppData\\Local\\Temp\\ipykernel_3228\\1788549698.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[word] = df['tokens'].apply(lambda x: x.count(word))\n",
      "C:\\Users\\LEGION\\AppData\\Local\\Temp\\ipykernel_3228\\1788549698.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[word] = df['tokens'].apply(lambda x: x.count(word))\n",
      "C:\\Users\\LEGION\\AppData\\Local\\Temp\\ipykernel_3228\\1788549698.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[word] = df['tokens'].apply(lambda x: x.count(word))\n",
      "C:\\Users\\LEGION\\AppData\\Local\\Temp\\ipykernel_3228\\1788549698.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[word] = df['tokens'].apply(lambda x: x.count(word))\n",
      "C:\\Users\\LEGION\\AppData\\Local\\Temp\\ipykernel_3228\\1788549698.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[word] = df['tokens'].apply(lambda x: x.count(word))\n",
      "C:\\Users\\LEGION\\AppData\\Local\\Temp\\ipykernel_3228\\1788549698.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[word] = df['tokens'].apply(lambda x: x.count(word))\n",
      "C:\\Users\\LEGION\\AppData\\Local\\Temp\\ipykernel_3228\\1788549698.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[word] = df['tokens'].apply(lambda x: x.count(word))\n",
      "C:\\Users\\LEGION\\AppData\\Local\\Temp\\ipykernel_3228\\1788549698.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[word] = df['tokens'].apply(lambda x: x.count(word))\n",
      "C:\\Users\\LEGION\\AppData\\Local\\Temp\\ipykernel_3228\\1788549698.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[word] = df['tokens'].apply(lambda x: x.count(word))\n",
      "C:\\Users\\LEGION\\AppData\\Local\\Temp\\ipykernel_3228\\1788549698.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[word] = df['tokens'].apply(lambda x: x.count(word))\n",
      "C:\\Users\\LEGION\\AppData\\Local\\Temp\\ipykernel_3228\\1788549698.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[word] = df['tokens'].apply(lambda x: x.count(word))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\LEGION\\AppData\\Local\\Temp\\ipykernel_3228\\1788549698.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[word] = df['tokens'].apply(lambda x: x.count(word))\n",
      "C:\\Users\\LEGION\\AppData\\Local\\Temp\\ipykernel_3228\\1788549698.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[word] = df['tokens'].apply(lambda x: x.count(word))\n",
      "C:\\Users\\LEGION\\AppData\\Local\\Temp\\ipykernel_3228\\1788549698.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[word] = df['tokens'].apply(lambda x: x.count(word))\n"
     ]
    }
   ],
   "source": [
    "for word in common_words_1:\n",
    "    df[word] = df['tokens'].apply(lambda x: x.count(word)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "id": "0f449835",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "import string\n",
    "import nltk\n",
    "import re\n",
    "\n",
    "text = df.title\n",
    "\n",
    "stopwords = nltk.corpus.stopwords.words('english')\n",
    "ps = nltk.PorterStemmer()\n",
    "\n",
    "# we set ngram_range for the CountVectorizer to get context around each word\n",
    "vectorizer = CountVectorizer(min_df=1, analyzer='word', ngram_range=(3, 3))\n",
    "\n",
    "# we create a function that will get rid of punctuations, tokenize, stem and remove stopwords\n",
    "def clean_text(text):\n",
    "    text = \"\".join([word.lower() for word in text if word not in string.punctuation])\n",
    "    tokens = re.split('\\W+', text)\n",
    "    text = [ps.stem(word) for word in tokens if word not in stopwords]\n",
    "    return text\n",
    "\n",
    "clean_text(text)\n",
    "\n",
    "# call `fit` to build the vocabulary\n",
    "vectorizer.fit(text)\n",
    "\n",
    "# call `transform` to convert text to a bag of words\n",
    "x = vectorizer.transform(text)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "id": "9d26a9ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.sparse import hstack\n",
    "#Create a function to get our X, y   \n",
    "def make_xy(data, vectorizer=None):  \n",
    "    if vectorizer is None:\n",
    "        vectorizer = CountVectorizer()\n",
    "    X = vectorizer.fit_transform(data.title)\n",
    "    X = X.tocsc()  # some versions of sklearn return COO format\n",
    "    y = data.trendingOrNot  \n",
    "    return X, y\n",
    "X, y = make_xy(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "id": "d33d5b4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Training Set: 0.8257491001070143\n",
      "Accuracy of Test Set: 0.786711415924899\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#Splitting our data into training and testing sets\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "clf = MultinomialNB()\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2)\n",
    "\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# Predict on the test data: y_pred\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "print(\"Accuracy of Training Set: {}\".format(clf.score(X_train, y_train)))\n",
    "print(\"Accuracy of Test Set: {}\".format(clf.score(X_test, y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "id": "c8f1615b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.29834917, 0.70165083]])"
      ]
     },
     "execution_count": 241,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.predict_proba(vectorizer.transform(['JUDAS AND THE BLACK MESSIAH - Official Trailer\t']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "id": "8a6b3b9a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>categoryId</th>\n",
       "      <th>tags</th>\n",
       "      <th>views</th>\n",
       "      <th>likes</th>\n",
       "      <th>comments</th>\n",
       "      <th>dayOfWeek</th>\n",
       "      <th>daytime</th>\n",
       "      <th>trendingOrNot</th>\n",
       "      <th>title_length</th>\n",
       "      <th>clean_title</th>\n",
       "      <th>clean_title_str</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>How To Make a Curried Egg Sandwich</td>\n",
       "      <td>26</td>\n",
       "      <td>how to make a curried egg sandwich|curried egg...</td>\n",
       "      <td>1238677.0</td>\n",
       "      <td>104736.0</td>\n",
       "      <td>13876.0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>34</td>\n",
       "      <td>[make, curried, egg, sandwich]</td>\n",
       "      <td>make curried egg sandwich</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Cake Rescue Fixing Viral Cake Fails | How To C...</td>\n",
       "      <td>24</td>\n",
       "      <td>cake rescue|caek fail|viral cake fails|funny c...</td>\n",
       "      <td>938198.0</td>\n",
       "      <td>44088.0</td>\n",
       "      <td>2409.0</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>75</td>\n",
       "      <td>[cake, rescue, fixing, viral, cake, fails, coo...</td>\n",
       "      <td>cake rescue fixing viral cake fails cook ann r...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Son, lemme teach you something new</td>\n",
       "      <td>24</td>\n",
       "      <td>[None]</td>\n",
       "      <td>1722152.0</td>\n",
       "      <td>169501.0</td>\n",
       "      <td>7263.0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>34</td>\n",
       "      <td>[son, lem, teach, something, new]</td>\n",
       "      <td>son lem teach something new</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Trump takes executive action to address econom...</td>\n",
       "      <td>25</td>\n",
       "      <td>president|trump|donald|executive|orders|stimul...</td>\n",
       "      <td>1090847.0</td>\n",
       "      <td>10922.0</td>\n",
       "      <td>9876.0</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>61</td>\n",
       "      <td>[trump, takes, executive, action, address, eco...</td>\n",
       "      <td>trump takes executive action address economy a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>JUDAS AND THE BLACK MESSIAH - Official Trailer</td>\n",
       "      <td>24</td>\n",
       "      <td>warner bros|warner brothers|wb|fred hampton|wi...</td>\n",
       "      <td>971704.0</td>\n",
       "      <td>23311.0</td>\n",
       "      <td>3240.0</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>46</td>\n",
       "      <td>[judas, black, messiah, official, trailer]</td>\n",
       "      <td>judas black messiah official trailer</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title  categoryId  \\\n",
       "0                 How To Make a Curried Egg Sandwich          26   \n",
       "1  Cake Rescue Fixing Viral Cake Fails | How To C...          24   \n",
       "2                 Son, lemme teach you something new          24   \n",
       "3  Trump takes executive action to address econom...          25   \n",
       "4     JUDAS AND THE BLACK MESSIAH - Official Trailer          24   \n",
       "\n",
       "                                                tags      views     likes  \\\n",
       "0  how to make a curried egg sandwich|curried egg...  1238677.0  104736.0   \n",
       "1  cake rescue|caek fail|viral cake fails|funny c...   938198.0   44088.0   \n",
       "2                                             [None]  1722152.0  169501.0   \n",
       "3  president|trump|donald|executive|orders|stimul...  1090847.0   10922.0   \n",
       "4  warner bros|warner brothers|wb|fred hampton|wi...   971704.0   23311.0   \n",
       "\n",
       "   comments  dayOfWeek  daytime  trendingOrNot  title_length  \\\n",
       "0   13876.0          4        1              1            34   \n",
       "1    2409.0          4        2              1            75   \n",
       "2    7263.0          3        1              1            34   \n",
       "3    9876.0          6        3              1            61   \n",
       "4    3240.0          3        3              1            46   \n",
       "\n",
       "                                         clean_title  \\\n",
       "0                     [make, curried, egg, sandwich]   \n",
       "1  [cake, rescue, fixing, viral, cake, fails, coo...   \n",
       "2                  [son, lem, teach, something, new]   \n",
       "3  [trump, takes, executive, action, address, eco...   \n",
       "4         [judas, black, messiah, official, trailer]   \n",
       "\n",
       "                                     clean_title_str  \n",
       "0                          make curried egg sandwich  \n",
       "1  cake rescue fixing viral cake fails cook ann r...  \n",
       "2                        son lem teach something new  \n",
       "3  trump takes executive action address economy a...  \n",
       "4               judas black messiah official trailer  "
      ]
     },
     "execution_count": 230,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "id": "dc6231b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "def cv_score(clf, X, y, scorefunc):\n",
    "    result = 0.\n",
    "    nfold = 5\n",
    "    for train, test in KFold(nfold).split(X): # split data into train/test groups, 5 times\n",
    "        clf.fit(X[train], y.iloc[train]) # fit the classifier, passed is as clf.\n",
    "        result += scorefunc(clf, X[test], y.iloc[test]) # evaluate score function on held-out data\n",
    "    return result / nfold # average"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "id": "5daddd4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def log_likelihood(clf, x, y):\n",
    "    prob = clf.predict_log_proba(x)\n",
    "    good = y \n",
    "    bad = ~good\n",
    "    return prob[good, 0].sum() + prob[bad, 1].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "id": "9434a612",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\LEGION\\AppData\\Local\\Temp\\ipykernel_13360\\2123442951.py:3: DeprecationWarning: `np.bool` is a deprecated alias for the builtin `bool`. To silence this warning, use `bool` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.bool_` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  mask = np.zeros(df.shape[0], dtype=np.bool)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "_, itest = train_test_split(range(df.shape[0]), train_size=0.7)\n",
    "mask = np.zeros(df.shape[0], dtype=np.bool)\n",
    "mask[itest] = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "id": "62207024",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "#the grid of parameters to search over\n",
    "alphas = [.1, 1, 5]\n",
    "min_dfs = [1]\n",
    "\n",
    "#Find the best value for alpha and min_df, and the best classifier\n",
    "best_alpha = None\n",
    "best_min_df = None\n",
    "maxscore=-np.inf\n",
    "for alpha in alphas:\n",
    "    for min_df in min_dfs:\n",
    "        vectorizer = CountVectorizer(min_df = min_df)\n",
    "        Xthis, ythis = make_xy(df, vectorizer)\n",
    "        Xtrainthis=Xthis[mask]\n",
    "        ytrainthis=ythis[mask]\n",
    "        clf = MultinomialNB(alpha=alpha)\n",
    "        cvscore = cv_score(clf, Xtrainthis, ytrainthis, log_likelihood)\n",
    "\n",
    "        if cvscore > maxscore:\n",
    "            maxscore = cvscore\n",
    "            best_alpha, best_min_df = alpha, min_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "id": "32090cc0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on training data: 0.875608\n",
      "Accuracy on test data:     0.768460\n"
     ]
    }
   ],
   "source": [
    "vectorizer = CountVectorizer(min_df=best_min_df)\n",
    "X, y = make_xy(df, vectorizer)\n",
    "xtrain=X[mask]\n",
    "ytrain=y[mask]\n",
    "xtest=X[~mask]\n",
    "ytest=y[~mask]\n",
    "\n",
    "clf = MultinomialNB(alpha=best_alpha).fit(xtrain, ytrain)\n",
    "\n",
    "#your turn. Print the accuracy on the test and training dataset\n",
    "training_accuracy = clf.score(xtrain, ytrain)\n",
    "test_accuracy = clf.score(xtest, ytest)\n",
    "\n",
    "print(\"Accuracy on training data: {:2f}\".format(training_accuracy))\n",
    "print(\"Accuracy on test data:     {:2f}\".format(test_accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "4eae84e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\LEGION\\anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:87: FutureWarning: Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.\n",
      "  warnings.warn(msg, category=FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Good words\t     P(good | word)\n",
      "                2022 0.99\n",
      "              shorts 0.99\n",
      "          highlights 0.98\n",
      "                2021 0.98\n",
      "           minecraft 0.98\n",
      "             oficial 0.97\n",
      "                2023 0.96\n",
      "                 ufc 0.96\n",
      "               among 0.95\n",
      "                  mv 0.95\n",
      "                 lil 0.95\n",
      "            survived 0.95\n",
      "            hardcore 0.95\n",
      "               built 0.94\n",
      "         hermitcraft 0.94\n",
      "                 nba 0.94\n",
      "                 000 0.94\n",
      "                 nbc 0.94\n",
      "              lakers 0.93\n",
      "                 bts 0.93\n",
      "                  24 0.92\n",
      "                  fc 0.92\n",
      "               music 0.92\n",
      "              reacts 0.92\n",
      "              tiktok 0.92\n",
      "              funkin 0.91\n",
      "                 cbs 0.91\n",
      "                ring 0.91\n",
      "            pregnant 0.91\n",
      "               elden 0.91\n",
      "           breakdown 0.91\n",
      "           challenge 0.91\n",
      "              roblox 0.90\n",
      "             genshin 0.90\n",
      "                 snl 0.90\n",
      "          manchester 0.90\n",
      "              reveal 0.90\n",
      "                fifa 0.90\n",
      "               lyric 0.90\n",
      "                guys 0.90\n",
      "                espn 0.90\n",
      "               wings 0.90\n",
      "                 pov 0.90\n",
      "            youngboy 0.90\n",
      "               dream 0.90\n",
      "              golazo 0.89\n",
      "              league 0.89\n",
      "             premier 0.89\n",
      "                 100 0.89\n",
      "                 him 0.89\n",
      "               spicy 0.89\n",
      "                 ksi 0.89\n",
      "              bought 0.89\n",
      "               debut 0.89\n",
      "                durk 0.89\n",
      "                 psg 0.89\n",
      "                 smp 0.89\n",
      "           barcelona 0.89\n",
      "            playtime 0.89\n",
      "           liverpool 0.89\n",
      "             sidemen 0.89\n",
      "               hours 0.88\n",
      "              united 0.88\n",
      "                 but 0.88\n",
      "               방탄소년단 0.88\n",
      "               poppy 0.88\n",
      "               queen 0.88\n",
      "                baby 0.88\n",
      "                loss 0.88\n",
      "               blind 0.88\n",
      "              amelio 0.88\n",
      "          basketball 0.88\n",
      "               twins 0.88\n",
      "                full 0.87\n",
      "               spent 0.87\n",
      "                  he 0.87\n",
      "                nets 0.87\n",
      "                 ucl 0.87\n",
      "             manhunt 0.87\n",
      "                2020 0.87\n",
      "         performance 0.87\n",
      "                 sec 0.87\n",
      "              billie 0.87\n",
      "                 tnt 0.87\n",
      "                seek 0.87\n",
      "            birthday 0.87\n",
      "               drake 0.87\n",
      "                went 0.87\n",
      "                 usa 0.87\n",
      "              sports 0.86\n",
      "               squid 0.86\n",
      "             cooking 0.86\n",
      "              eilish 0.86\n",
      "          undisputed 0.86\n",
      "               dixie 0.86\n",
      "                 mod 0.86\n",
      "                 cat 0.86\n",
      "                food 0.86\n",
      "            extended 0.86\n",
      "                  ft 0.86\n",
      "Bad words\t     P(good | word)\n",
      "                leak 0.22\n",
      "             station 0.21\n",
      "                  e3 0.21\n",
      "             expanse 0.21\n",
      "            giveaway 0.21\n",
      "                 anh 0.21\n",
      "                 cho 0.21\n",
      "           transport 0.21\n",
      "               lapse 0.21\n",
      "            probably 0.21\n",
      "                tale 0.21\n",
      "              gaming 0.20\n",
      "             thrones 0.20\n",
      "             tractor 0.20\n",
      "          discussion 0.20\n",
      "              hubble 0.20\n",
      "           tailosive 0.20\n",
      "      reorchestrated 0.20\n",
      "               movie 0.20\n",
      "            handmaid 0.20\n",
      "               games 0.20\n",
      "                play 0.20\n",
      "                 ios 0.20\n",
      "                 suv 0.20\n",
      "             english 0.20\n",
      "              gerard 0.20\n",
      "              driver 0.20\n",
      "             fallout 0.19\n",
      "                 360 0.19\n",
      "             angular 0.19\n",
      "                cách 0.19\n",
      "              beyond 0.19\n",
      "               madea 0.18\n",
      "                 sun 0.18\n",
      "         predictions 0.18\n",
      "            illenium 0.18\n",
      "               perry 0.17\n",
      "           streaming 0.17\n",
      "                tech 0.17\n",
      "        construction 0.17\n",
      "              review 0.17\n",
      "              gamers 0.17\n",
      "                2013 0.17\n",
      "           astronomy 0.17\n",
      "                  tv 0.17\n",
      "                2010 0.16\n",
      "                 buy 0.16\n",
      "             harvard 0.15\n",
      "                 iss 0.15\n",
      "                 101 0.15\n",
      "               cargo 0.15\n",
      "             batería 0.14\n",
      "                 top 0.14\n",
      "               space 0.14\n",
      "       international 0.14\n",
      "                 4x4 0.14\n",
      "               touch 0.14\n",
      "                  3d 0.14\n",
      "              indeed 0.13\n",
      "                tame 0.13\n",
      "           discovery 0.13\n",
      "              undead 0.13\n",
      "                nasa 0.13\n",
      "                wait 0.13\n",
      "          statistics 0.13\n",
      "              nooner 0.13\n",
      "                  và 0.12\n",
      "             evolved 0.12\n",
      "           simulator 0.11\n",
      "           reactions 0.11\n",
      "                 hls 0.11\n",
      "                rant 0.11\n",
      "                drum 0.11\n",
      "                clip 0.11\n",
      "                 ark 0.11\n",
      "                sale 0.11\n",
      "             driving 0.10\n",
      "                trek 0.10\n",
      "             madonna 0.10\n",
      "           anonymous 0.10\n",
      "           paramount 0.09\n",
      "                  hd 0.08\n",
      "                hulu 0.08\n",
      "                 ps4 0.08\n",
      "          featurette 0.08\n",
      "              mobile 0.08\n",
      "                2015 0.07\n",
      "                spot 0.06\n",
      "             netflix 0.06\n",
      "            pictures 0.06\n",
      "             offroad 0.05\n",
      "                rent 0.05\n",
      "                  qn 0.04\n",
      "                 bảo 0.04\n",
      "                bình 0.04\n",
      "                2016 0.03\n",
      "                2019 0.03\n",
      "                2018 0.03\n",
      "             android 0.03\n",
      "                2017 0.03\n"
     ]
    }
   ],
   "source": [
    "words = np.array(vectorizer.get_feature_names())\n",
    "\n",
    "x = np.eye(xtest.shape[1])\n",
    "probs = clf.predict_log_proba(x)[:, 0]\n",
    "ind = np.argsort(probs)\n",
    "\n",
    "good_words = words[ind[:100]]\n",
    "bad_words = words[ind[-100:]]\n",
    "\n",
    "good_prob = probs[ind[:100]]\n",
    "bad_prob = probs[ind[-100:]]\n",
    "\n",
    "print(\"Good words\\t     P(good | word)\")\n",
    "for w, p in zip(good_words, good_prob):\n",
    "    print(\"{:>20}\".format(w), \"{:.2f}\".format(1 - np.exp(p)))\n",
    "    \n",
    "print(\"Bad words\\t     P(good | word)\")\n",
    "for w, p in zip(bad_words, bad_prob):\n",
    "    print(\"{:>20}\".format(w), \"{:.2f}\".format(1 - np.exp(p)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "32ee10b9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.46509481, 0.53490519]])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.predict_proba(vectorizer.transform(['']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "b38726d8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('tfidf', TfidfVectorizer()), ('clf', MultinomialNB())])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.model_selection import train_test_split\n",
    "X = df[['title']]\n",
    "y = df.trendingOrNot\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y,test_size = 0.2)\n",
    "# X_train, X_test, y_train, y_test = train_test_split(os_data_X, os_data_y,test_size = 0.2)\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "count_vect = CountVectorizer()\n",
    "X_train_counts = count_vect.fit_transform(X_train)\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "tfidf_transformer = TfidfTransformer()\n",
    "X_train_tfidf = tfidf_transformer.fit_transform(X_train_counts)\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "text_clf = Pipeline([('tfidf',TfidfVectorizer()),('clf',MultinomialNB())])\n",
    "X_train = X_train['title'].values.ravel()\n",
    "text_clf.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "4f39e4d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7887056763461258\n"
     ]
    }
   ],
   "source": [
    "accuracy = text_clf.score(X_test['title'], y_test)\n",
    "print('Accuracy:', accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "4dffad1e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "55375              Incredible Solar Explosions #Sun #Shorts\n",
       "7709         Ever Given UPDATE 28 March Operation Backtwist\n",
       "50200     BMW X7 City Driving Simulator - Police Offroad...\n",
       "30340      Japan vs. Spain Highlights | 2022 FIFA World Cup\n",
       "76706     10 Facts You Don't Know About Every Pokémon Ge...\n",
       "                                ...                        \n",
       "41130         Jack Harlow - ONCE MAY COMES [Official Audio]\n",
       "101202        Sea cucumbers, hummus, bagels 🥯 , blue cheese\n",
       "97162                                           Live 8/4/18\n",
       "9734                               Meek Mill - Flamerz Flow\n",
       "69452     Atlanta Hawks vs. Boston Celtics Full Highligh...\n",
       "Name: title, Length: 20559, dtype: object"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test['title']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "ed2e54d9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "55375     0\n",
       "7709      1\n",
       "50200     0\n",
       "30340     1\n",
       "76706     0\n",
       "         ..\n",
       "41130     0\n",
       "101202    0\n",
       "97162     0\n",
       "9734      1\n",
       "69452     0\n",
       "Name: trendingOrNot, Length: 20559, dtype: int64"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "601ad137",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0], dtype=int64)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "text_clf.predict(['Top 10 Best Places to Visit in Japan'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "bc02d3f7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('tfidf', TfidfVectorizer()), ('clf', SVC())])"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import train_test_split\n",
    "X = merged_df[['tags_clean']]\n",
    "y = merged_df.trendingOrNot\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y,test_size = 0.2)\n",
    "# X_train, X_test, y_train, y_test = train_test_split(os_data_X, os_data_y,test_size = 0.2)\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "count_vect = CountVectorizer()\n",
    "X_train_counts = count_vect.fit_transform(X_train)\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "tfidf_transformer = TfidfTransformer()\n",
    "X_train_tfidf = tfidf_transformer.fit_transform(X_train_counts)\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "text_clf = Pipeline([('tfidf',TfidfVectorizer()),('clf',SVC())])\n",
    "X_train = X_train['tags_clean'].values.ravel()\n",
    "text_clf.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "7aa22800",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "48965    Story Work Pay Per Click Website Category Heal...\n",
       "58059    thinkhero Captain America Fictional Character ...\n",
       "34211                             sonic sonic the hedgehog\n",
       "4421     ChrisFix coolant antifreeze engine car how to ...\n",
       "42176    Netflix Trailer Netflix Original Series Netfli...\n",
       "                               ...                        \n",
       "33683    Telemundo Deportes Liverpool Manchester United...\n",
       "43235    hulu Stephen King Friday the 13th Horror jj ab...\n",
       "50067    webdev app development lesson tutorial angular...\n",
       "38288    ghost in the shell ghost in the shell trailer ...\n",
       "32916                                       golf good good\n",
       "Name: tags_clean, Length: 12213, dtype: object"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test['tags_clean']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "96b493c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9649553754196348\n"
     ]
    }
   ],
   "source": [
    "accuracy = text_clf.score(X_test['tags_clean'], y_test)\n",
    "print('Accuracy:', accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "14ad12f7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1], dtype=int64)"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "text_clf.predict(['sonic'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94752591",
   "metadata": {},
   "source": [
    "# Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "2683391b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>categoryId</th>\n",
       "      <th>dayOfWeek</th>\n",
       "      <th>daytime</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>categoryId</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.009481</td>\n",
       "      <td>-0.044329</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dayOfWeek</th>\n",
       "      <td>-0.009481</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.015999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>daytime</th>\n",
       "      <td>-0.044329</td>\n",
       "      <td>0.015999</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            categoryId  dayOfWeek   daytime\n",
       "categoryId    1.000000  -0.009481 -0.044329\n",
       "dayOfWeek    -0.009481   1.000000  0.015999\n",
       "daytime      -0.044329   0.015999  1.000000"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfCorr = merged_df[['categoryId','dayOfWeek','daytime']].corr()\n",
    "dfCorr\n",
    "# sns.heatmap(dfCorr,annot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "2c748199",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>videoID</th>\n",
       "      <th>title</th>\n",
       "      <th>publishedAt</th>\n",
       "      <th>channelId</th>\n",
       "      <th>channelTitle</th>\n",
       "      <th>categoryId</th>\n",
       "      <th>tags</th>\n",
       "      <th>views</th>\n",
       "      <th>likes</th>\n",
       "      <th>comments</th>\n",
       "      <th>description</th>\n",
       "      <th>untilTrend</th>\n",
       "      <th>trendingOrNot</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>cAtazIk1IYw</td>\n",
       "      <td>How To Make a Curried Egg Sandwich</td>\n",
       "      <td>2020-08-07 18:30:06+00:00</td>\n",
       "      <td>UCR4s1DE9J4DHzZYXMltSMAg</td>\n",
       "      <td>HowToBasic</td>\n",
       "      <td>26</td>\n",
       "      <td>how to make a curried egg sandwich|curried egg...</td>\n",
       "      <td>1238677.0</td>\n",
       "      <td>104736.0</td>\n",
       "      <td>13876.0</td>\n",
       "      <td>Today I show you how to make a curried egg san...</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       videoID                               title               publishedAt  \\\n",
       "0  cAtazIk1IYw  How To Make a Curried Egg Sandwich 2020-08-07 18:30:06+00:00   \n",
       "\n",
       "                  channelId channelTitle  categoryId  \\\n",
       "0  UCR4s1DE9J4DHzZYXMltSMAg   HowToBasic          26   \n",
       "\n",
       "                                                tags      views     likes  \\\n",
       "0  how to make a curried egg sandwich|curried egg...  1238677.0  104736.0   \n",
       "\n",
       "   comments                                        description  untilTrend  \\\n",
       "0   13876.0  Today I show you how to make a curried egg san...           4   \n",
       "\n",
       "   trendingOrNot  \n",
       "0              1  "
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged_df.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "fdcd547c",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df[['categoryId', 'views', 'likes', 'comments', 'dayOfWeek','duration']]\n",
    "y = df['trendingOrNot']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "6286f37b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dayOfWeek     2.165008e-42\n",
       "categoryId    0.000000e+00\n",
       "views         0.000000e+00\n",
       "likes         0.000000e+00\n",
       "comments      0.000000e+00\n",
       "duration      0.000000e+00\n",
       "dtype: float64"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Categorical Feature(Chi-Squared Test)\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_selection import chi2\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y,test_size = 0.3,random_state=123)\n",
    "\n",
    "f_score=chi2(X_train,y_train)\n",
    "\n",
    "pvalues = pd.Series(f_score[1])\n",
    "pvalues.index = X_train.columns\n",
    "pvalues.sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "71d4c279",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['likes', 'comments'], dtype=object)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Regularization-based Feature Selection(L1 (Lasso) / L2(Ridge))\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y,test_size = 0.3,random_state=123)\n",
    "\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "\n",
    "sel = SelectFromModel(LogisticRegression(penalty=\"l2\",C=1,solver=\"liblinear\"))\n",
    "\n",
    "sel.fit(X_train,y_train)\n",
    "\n",
    "sel.get_feature_names_out()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "34cb19f1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "duration        0.059012\n",
       "categoryId      0.044644\n",
       "title_length    0.022751\n",
       "dayOfWeek       0.005229\n",
       "daytime         0.004172\n",
       "dtype: float64"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Mutual Information\n",
    "from sklearn.feature_selection import mutual_info_classif\n",
    "from sklearn.model_selection import train_test_split\n",
    "X = df[['categoryId',  'dayOfWeek','daytime','title_length','duration']]\n",
    "y = df['trendingOrNot']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y,test_size = 0.3,random_state=123)\n",
    "mutual_info = mutual_info_classif(X_train,y_train)\n",
    "mutual_info = pd.Series(mutual_info)\n",
    "mutual_info.index = X_train.columns\n",
    "mutual_info.sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "5bafcd89",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RFE(estimator=DecisionTreeClassifier(), n_features_to_select=2)"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Recursive Feature Elimination(RFE)\n",
    "\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "X = df[['categoryId',  'dayOfWeek','daytime','title_length','duration']]\n",
    "y = df['trendingOrNot']\n",
    "\n",
    "rfe = RFE(estimator=DecisionTreeClassifier(),n_features_to_select=2)\n",
    "rfe.fit(X,y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "ea5dca58",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "categoryId selected=False rank=2\n",
      "dayOfWeek selected=False rank=3\n",
      "daytime selected=False rank=4\n",
      "title_length selected=True rank=1\n",
      "duration selected=True rank=1\n"
     ]
    }
   ],
   "source": [
    "for i, col in enumerate(X.columns):\n",
    "    print(f\"{col} selected={rfe.support_[i]} rank={rfe.ranking_[i]}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "7eafb8db",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Select columns for correlation analysis\n",
    "cols = ['categoryId', 'dayOfWeek', 'daytime', 'title_length', 'duration']\n",
    "corr_matrix = df[cols].corr()\n",
    "\n",
    "# Plot heatmap of correlation matrix\n",
    "sns.heatmap(corr_matrix, cmap='coolwarm', annot=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7197614",
   "metadata": {},
   "source": [
    "# Classification (Logistic Regression)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "id": "ed40b361",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0x1afdf91ba00>"
      ]
     },
     "execution_count": 220,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.scatter(df.categoryId,df.trendingOrNot,color='red')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "d52c8f75",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['title', 'categoryId', 'tags', 'views', 'likes', 'comments',\n",
       "       'dayOfWeek', 'trendingOrNot'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "d5353163",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X = df[['categoryId','dayOfWeek','daytime','title_length','duration']]\n",
    "y = df.trendingOrNot\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y,test_size = 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "4cdab10e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>views</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>21445</th>\n",
       "      <td>2317110.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2502</th>\n",
       "      <td>686554.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36282</th>\n",
       "      <td>110103.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38397</th>\n",
       "      <td>35856.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1688</th>\n",
       "      <td>482856.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20435</th>\n",
       "      <td>551663.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3518</th>\n",
       "      <td>1115902.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50524</th>\n",
       "      <td>798203.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25639</th>\n",
       "      <td>2878055.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26977</th>\n",
       "      <td>604678.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>30952 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           views\n",
       "21445  2317110.0\n",
       "2502    686554.0\n",
       "36282   110103.0\n",
       "38397    35856.0\n",
       "1688    482856.0\n",
       "...          ...\n",
       "20435   551663.0\n",
       "3518   1115902.0\n",
       "50524   798203.0\n",
       "25639  2878055.0\n",
       "26977   604678.0\n",
       "\n",
       "[30952 rows x 1 columns]"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "d83e8808",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.738715816031987"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "model = LogisticRegression()\n",
    "model.fit(X_train,y_train)\n",
    "\n",
    "model.score(X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "3cd70c5c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, ..., 0, 0, 0], dtype=int64)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "bae721d0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.73216023, 0.26783977],\n",
       "       [0.83297616, 0.16702384],\n",
       "       [0.61271336, 0.38728664],\n",
       "       ...,\n",
       "       [0.56377132, 0.43622868],\n",
       "       [0.87162221, 0.12837779],\n",
       "       [0.84560732, 0.15439268]])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict_proba(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "3385791b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>categoryId</th>\n",
       "      <th>dayOfWeek</th>\n",
       "      <th>daytime</th>\n",
       "      <th>title_length</th>\n",
       "      <th>duration</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>63358</th>\n",
       "      <td>24</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>45</td>\n",
       "      <td>1755.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7012</th>\n",
       "      <td>26</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>75</td>\n",
       "      <td>462.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1668</th>\n",
       "      <td>27</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>16</td>\n",
       "      <td>64.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88710</th>\n",
       "      <td>24</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>87</td>\n",
       "      <td>64.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56137</th>\n",
       "      <td>20</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>39</td>\n",
       "      <td>506.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99944</th>\n",
       "      <td>22</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>41</td>\n",
       "      <td>337.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51681</th>\n",
       "      <td>24</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>56</td>\n",
       "      <td>1027.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85052</th>\n",
       "      <td>20</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>38</td>\n",
       "      <td>891.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84526</th>\n",
       "      <td>24</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>99</td>\n",
       "      <td>311.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94647</th>\n",
       "      <td>22</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>75</td>\n",
       "      <td>608.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>46769 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       categoryId  dayOfWeek  daytime  title_length  duration\n",
       "63358          24          4        1            45    1755.0\n",
       "7012           26          6        1            75     462.0\n",
       "1668           27          1        0            16      64.0\n",
       "88710          24          0        3            87      64.0\n",
       "56137          20          5        1            39     506.0\n",
       "...           ...        ...      ...           ...       ...\n",
       "99944          22          2        1            41     337.0\n",
       "51681          24          0        1            56    1027.0\n",
       "85052          20          4        0            38     891.0\n",
       "84526          24          4        0            99     311.0\n",
       "94647          22          2        3            75     608.0\n",
       "\n",
       "[46769 rows x 5 columns]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "12f22936",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "63358    0\n",
       "7012     0\n",
       "1668     0\n",
       "88710    0\n",
       "56137    1\n",
       "        ..\n",
       "99944    0\n",
       "51681    1\n",
       "85052    0\n",
       "84526    0\n",
       "94647    1\n",
       "Name: trendingOrNot, Length: 46769, dtype: int64"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d17f11e7",
   "metadata": {},
   "source": [
    "# Classfication (SVC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "a5ab6e2e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['title', 'categoryId', 'tags', 'views', 'likes', 'comments',\n",
       "       'dayOfWeek', 'daytime', 'trendingOrNot'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "9917ed41",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7004718128313634"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "X = df[['categoryId','dayOfWeek','daytime']]\n",
    "y = df.trendingOrNot\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y,test_size = 0.2)\n",
    "# X_train, X_test, y_train, y_test = train_test_split(os_data_X, os_data_y,test_size = 0.2)\n",
    "model = SVC()\n",
    "\n",
    "model.fit(X_train,y_train)\n",
    "\n",
    "model.score(X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "14045557",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "17643     1\n",
       "32027     1\n",
       "21663     1\n",
       "21869     1\n",
       "101916    0\n",
       "         ..\n",
       "66837     0\n",
       "31568     1\n",
       "10673     1\n",
       "20325     1\n",
       "20230     1\n",
       "Name: trendingOrNot, Length: 20559, dtype: int64"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "c844471b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\LEGION\\anaconda3\\lib\\site-packages\\sklearn\\base.py:450: UserWarning: X does not have valid feature names, but SVC was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0], dtype=int64)"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test = np.array([[200000, 40000, 50000,1]])\n",
    "\n",
    "model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "14a9167f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9331859493981822\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import train_test_split\n",
    "# Split data into training and testing sets\n",
    "X = merged_df[['title']]\n",
    "y = merged_df.trendingOrNot\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
    "\n",
    "# Create a pipeline object with CountVectorizer, TfidfTransformer, and SVM\n",
    "text_clf = Pipeline([\n",
    "    ('vect', CountVectorizer()),\n",
    "    ('tfidf', TfidfTransformer()),\n",
    "    ('clf', SVC())\n",
    "])\n",
    "\n",
    "# Fit the pipeline object on the training data\n",
    "text_clf.fit(X_train['title'], y_train)\n",
    "\n",
    "# Predict on the testing data\n",
    "y_pred = text_clf.predict(X_test['title'])\n",
    "\n",
    "# Evaluate the performance of the classifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print('Accuracy:', accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "a6916396",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 1, 1], dtype=int64)"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "42fc39a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9331859493981822\n"
     ]
    }
   ],
   "source": [
    "test = text_clf.predict(X_test['title'])\n",
    "from sklearn.metrics import accuracy_score\n",
    "accuracy = accuracy_score(y_test, test)\n",
    "print('Accuracy:', accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "48e9a346",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('tfidf', TfidfVectorizer()), ('clf', SVC())])"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import train_test_split\n",
    "X = merged_df[['title']]\n",
    "y = merged_df.trendingOrNot\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y,test_size = 0.2)\n",
    "# X_train, X_test, y_train, y_test = train_test_split(os_data_X, os_data_y,test_size = 0.2)\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "count_vect = CountVectorizer()\n",
    "X_train_counts = count_vect.fit_transform(X_train)\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "tfidf_transformer = TfidfTransformer()\n",
    "X_train_tfidf = tfidf_transformer.fit_transform(X_train_counts)\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "text_clf = Pipeline([('tfidf',TfidfVectorizer()),('clf',SVC())])\n",
    "X_train = X_train['title'].values.ravel()\n",
    "text_clf.fit(X_train,y_train)\n",
    "# model = SVC()\n",
    "\n",
    "# model.fit(X_train,y_train)\n",
    "\n",
    "# model.score(X_test,y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "5e6cc3bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9307002665374364\n"
     ]
    }
   ],
   "source": [
    "accuracy = text_clf.score(X_test['title'], y_test)\n",
    "print('Accuracy:', accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "38173a21",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13964                    Wildest Dreams (Taylor's Version)\n",
       "24250    The Netherlands upset Belgium 4-1 behind two g...\n",
       "55563              Top 10 Pokémon With TERRIBLE Evolutions\n",
       "57753    Review Game Blade & Soul Revolution Mobile | B...\n",
       "46189    CYBERPUNK 2077 NEW DETAILS, PARENTS ARE HIRING...\n",
       "                               ...                        \n",
       "49527    Epic is Suing This Fortnite Hacker Because Of ...\n",
       "61788    Affordable Skincare Routine for Acne Prone Ski...\n",
       "24214    Kambosos & Haney Have Explosive Faceoff Interv...\n",
       "25854                Thor: Love and Thunder - Movie Review\n",
       "38483    You're Next (2013) - 'Really Scary' TV Spot #1...\n",
       "Name: title, Length: 12381, dtype: object"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test['title']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "7c291c55",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC()"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_res, y_res,test_size = 0.2)\n",
    "model = SVC()\n",
    "\n",
    "model.fit(X_train,y_train)\n",
    "model.score(X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "744fd2a2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 1, 1, 1, 0, 0, 1, 0, 0], dtype=int64)"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(X_test[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "4ed61cf7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>views</th>\n",
       "      <th>likes</th>\n",
       "      <th>comments</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>39437</th>\n",
       "      <td>11603.0</td>\n",
       "      <td>142.0</td>\n",
       "      <td>15.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58087</th>\n",
       "      <td>20821.0</td>\n",
       "      <td>452.0</td>\n",
       "      <td>66.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5664</th>\n",
       "      <td>3624294.0</td>\n",
       "      <td>27022.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16079</th>\n",
       "      <td>487135.0</td>\n",
       "      <td>24571.0</td>\n",
       "      <td>913.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10325</th>\n",
       "      <td>4333597.0</td>\n",
       "      <td>46787.0</td>\n",
       "      <td>1435.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24408</th>\n",
       "      <td>342153.0</td>\n",
       "      <td>13645.0</td>\n",
       "      <td>1434.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1079</th>\n",
       "      <td>804912.0</td>\n",
       "      <td>34227.0</td>\n",
       "      <td>1575.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31393</th>\n",
       "      <td>1913570.0</td>\n",
       "      <td>123233.0</td>\n",
       "      <td>12503.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22400</th>\n",
       "      <td>964524.0</td>\n",
       "      <td>8326.0</td>\n",
       "      <td>1361.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45852</th>\n",
       "      <td>5584702.0</td>\n",
       "      <td>103317.0</td>\n",
       "      <td>3695.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>12381 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           views     likes  comments\n",
       "39437    11603.0     142.0      15.0\n",
       "58087    20821.0     452.0      66.0\n",
       "5664   3624294.0   27022.0       0.0\n",
       "16079   487135.0   24571.0     913.0\n",
       "10325  4333597.0   46787.0    1435.0\n",
       "...          ...       ...       ...\n",
       "24408   342153.0   13645.0    1434.0\n",
       "1079    804912.0   34227.0    1575.0\n",
       "31393  1913570.0  123233.0   12503.0\n",
       "22400   964524.0    8326.0    1361.0\n",
       "45852  5584702.0  103317.0    3695.0\n",
       "\n",
       "[12381 rows x 3 columns]"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec04ab6f",
   "metadata": {},
   "source": [
    "# Cross-Validation (K-Fold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ce65ba0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_score (model, X_train,X_test,y_train,y_test):\n",
    "    model.fit(X_train,y_train)\n",
    "    return model.score(X_test,y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6517ebde",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "scores = cross_val_score(model,X_train,y_train,scoring='r2',cv = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e59f15c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_predict\n",
    "\n",
    "pred = cross_val_predict(model.fit(X_train,y_train),X_test,y_test)\n",
    "\n",
    "scores_test = cross_val_score(model,X_test,y_test,cv = 10)\n",
    "np.mean(scores_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e7c2fae",
   "metadata": {},
   "source": [
    "# Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b8782f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "clf = GridSearchCV(svm.SVC(gamma='auto'),{\n",
    "    'C':[1,10,20],\n",
    "    'kernel':['rbf','linear']\n",
    "},cv=5, return_train_score=False)\n",
    "clf.fit(X_train,X_test)\n",
    "clf.cv_results_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d51d72a",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = pd.DataFrame(clf.cv_results_)\n",
    "df['param_C','param_kernel','mean_test_score']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c130140a",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36cdffae",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_params = {\n",
    "    model_params = {\n",
    "    'svm': {\n",
    "        'model': svm.SVC(gamma='auto'),\n",
    "        'params' : {\n",
    "            'C': [1,10,20],\n",
    "            'kernel': ['rbf','linear']\n",
    "        }  \n",
    "    },\n",
    "    'random_forest': {\n",
    "        'model': RandomForestClassifier(),\n",
    "        'params' : {\n",
    "            'n_estimators': [1,5,10]\n",
    "        }\n",
    "    },\n",
    "    'logistic_regression' : {\n",
    "        'model': LogisticRegression(solver='liblinear',multi_class='auto'),\n",
    "        'params': {\n",
    "            'C': [1,5,10]\n",
    "        }\n",
    "    }\n",
    "}\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87473382",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "scores = []\n",
    "\n",
    "for model_name, mp in model_params.items():\n",
    "    clf =  GridSearchCV(mp['model'], mp['params'], cv=5, return_train_score=False)\n",
    "    clf.fit(iris.data, iris.target)\n",
    "    scores.append({\n",
    "        'model': model_name,\n",
    "        'best_score': clf.best_score_,\n",
    "        'best_params': clf.best_params_\n",
    "    })\n",
    "    \n",
    "df = pd.DataFrame(scores,columns=['model','best_score','best_params'])\n",
    "df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
